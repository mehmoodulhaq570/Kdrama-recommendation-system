[
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "Counter",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "FastAPI",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "Query",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "HTTPException",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "status",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "CORSMiddleware",
        "importPath": "fastapi.middleware.cors",
        "description": "fastapi.middleware.cors",
        "isExtraImport": true,
        "detail": "fastapi.middleware.cors",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "pickle",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pickle",
        "description": "pickle",
        "detail": "pickle",
        "documentation": {}
    },
    {
        "label": "faiss",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "faiss",
        "description": "faiss",
        "detail": "faiss",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "SentenceTransformer",
        "importPath": "sentence_transformers",
        "description": "sentence_transformers",
        "isExtraImport": true,
        "detail": "sentence_transformers",
        "documentation": {}
    },
    {
        "label": "CrossEncoder",
        "importPath": "sentence_transformers",
        "description": "sentence_transformers",
        "isExtraImport": true,
        "detail": "sentence_transformers",
        "documentation": {}
    },
    {
        "label": "SentenceTransformer",
        "importPath": "sentence_transformers",
        "description": "sentence_transformers",
        "isExtraImport": true,
        "detail": "sentence_transformers",
        "documentation": {}
    },
    {
        "label": "SentenceTransformer",
        "importPath": "sentence_transformers",
        "description": "sentence_transformers",
        "isExtraImport": true,
        "detail": "sentence_transformers",
        "documentation": {}
    },
    {
        "label": "SentenceTransformer",
        "importPath": "sentence_transformers",
        "description": "sentence_transformers",
        "isExtraImport": true,
        "detail": "sentence_transformers",
        "documentation": {}
    },
    {
        "label": "InputExample",
        "importPath": "sentence_transformers",
        "description": "sentence_transformers",
        "isExtraImport": true,
        "detail": "sentence_transformers",
        "documentation": {}
    },
    {
        "label": "losses",
        "importPath": "sentence_transformers",
        "description": "sentence_transformers",
        "isExtraImport": true,
        "detail": "sentence_transformers",
        "documentation": {}
    },
    {
        "label": "SentenceTransformer",
        "importPath": "sentence_transformers",
        "description": "sentence_transformers",
        "isExtraImport": true,
        "detail": "sentence_transformers",
        "documentation": {}
    },
    {
        "label": "process",
        "importPath": "rapidfuzz",
        "description": "rapidfuzz",
        "isExtraImport": true,
        "detail": "rapidfuzz",
        "documentation": {}
    },
    {
        "label": "fuzz",
        "importPath": "rapidfuzz",
        "description": "rapidfuzz",
        "isExtraImport": true,
        "detail": "rapidfuzz",
        "documentation": {}
    },
    {
        "label": "lru_cache",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "BM25Plus",
        "importPath": "rank_bm25",
        "description": "rank_bm25",
        "isExtraImport": true,
        "detail": "rank_bm25",
        "documentation": {}
    },
    {
        "label": "uuid",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "uuid",
        "description": "uuid",
        "detail": "uuid",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "QueryAnalyzer",
        "importPath": "query_analyzer",
        "description": "query_analyzer",
        "isExtraImport": true,
        "detail": "query_analyzer",
        "documentation": {}
    },
    {
        "label": "get_search_strategy",
        "importPath": "query_analyzer",
        "description": "query_analyzer",
        "isExtraImport": true,
        "detail": "query_analyzer",
        "documentation": {}
    },
    {
        "label": "QueryAnalyzer",
        "importPath": "query_analyzer",
        "description": "query_analyzer",
        "isExtraImport": true,
        "detail": "query_analyzer",
        "documentation": {}
    },
    {
        "label": "QueryAnalyzer",
        "importPath": "query_analyzer",
        "description": "query_analyzer",
        "isExtraImport": true,
        "detail": "query_analyzer",
        "documentation": {}
    },
    {
        "label": "get_tracker",
        "importPath": "analytics",
        "description": "analytics",
        "isExtraImport": true,
        "detail": "analytics",
        "documentation": {}
    },
    {
        "label": "get_profile_manager",
        "importPath": "user_profile",
        "description": "user_profile",
        "isExtraImport": true,
        "detail": "user_profile",
        "documentation": {}
    },
    {
        "label": "UserProfileManager",
        "importPath": "user_profile",
        "description": "user_profile",
        "isExtraImport": true,
        "detail": "user_profile",
        "documentation": {}
    },
    {
        "label": "UserProfileManager",
        "importPath": "user_profile",
        "description": "user_profile",
        "isExtraImport": true,
        "detail": "user_profile",
        "documentation": {}
    },
    {
        "label": "get_personalization_engine",
        "importPath": "personalization",
        "description": "personalization",
        "isExtraImport": true,
        "detail": "personalization",
        "documentation": {}
    },
    {
        "label": "PersonalizationEngine",
        "importPath": "personalization",
        "description": "personalization",
        "isExtraImport": true,
        "detail": "personalization",
        "documentation": {}
    },
    {
        "label": "math",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "math",
        "description": "math",
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "aiohttp",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "aiohttp",
        "description": "aiohttp",
        "detail": "aiohttp",
        "documentation": {}
    },
    {
        "label": "asyncio",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "asyncio",
        "description": "asyncio",
        "detail": "asyncio",
        "documentation": {}
    },
    {
        "label": "aiofiles",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "aiofiles",
        "description": "aiofiles",
        "detail": "aiofiles",
        "documentation": {}
    },
    {
        "label": "random",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "random",
        "description": "random",
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm.asyncio",
        "description": "tqdm.asyncio",
        "isExtraImport": true,
        "detail": "tqdm.asyncio",
        "documentation": {}
    },
    {
        "label": "urlparse",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "csv",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "csv",
        "description": "csv",
        "detail": "csv",
        "documentation": {}
    },
    {
        "label": "ThreadPoolExecutor",
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "isExtraImport": true,
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "as_completed",
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "isExtraImport": true,
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "html",
        "importPath": "lxml",
        "description": "lxml",
        "isExtraImport": true,
        "detail": "lxml",
        "documentation": {}
    },
    {
        "label": "async_playwright",
        "importPath": "playwright.async_api",
        "description": "playwright.async_api",
        "isExtraImport": true,
        "detail": "playwright.async_api",
        "documentation": {}
    },
    {
        "label": "Route",
        "importPath": "playwright.async_api",
        "description": "playwright.async_api",
        "isExtraImport": true,
        "detail": "playwright.async_api",
        "documentation": {}
    },
    {
        "label": "TimeoutError",
        "importPath": "playwright.async_api",
        "description": "playwright.async_api",
        "isExtraImport": true,
        "detail": "playwright.async_api",
        "documentation": {}
    },
    {
        "label": "async_playwright",
        "importPath": "playwright.async_api",
        "description": "playwright.async_api",
        "isExtraImport": true,
        "detail": "playwright.async_api",
        "documentation": {}
    },
    {
        "label": "BeautifulSoup",
        "importPath": "bs4",
        "description": "bs4",
        "isExtraImport": true,
        "detail": "bs4",
        "documentation": {}
    },
    {
        "label": "BeautifulSoup",
        "importPath": "bs4",
        "description": "bs4",
        "isExtraImport": true,
        "detail": "bs4",
        "documentation": {}
    },
    {
        "label": "BeautifulSoup",
        "importPath": "bs4",
        "description": "bs4",
        "isExtraImport": true,
        "detail": "bs4",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "sync_playwright",
        "importPath": "playwright.sync_api",
        "description": "playwright.sync_api",
        "isExtraImport": true,
        "detail": "playwright.sync_api",
        "documentation": {}
    },
    {
        "label": "requests",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "requests",
        "description": "requests",
        "detail": "requests",
        "documentation": {}
    },
    {
        "label": "webdriver",
        "importPath": "selenium",
        "description": "selenium",
        "isExtraImport": true,
        "detail": "selenium",
        "documentation": {}
    },
    {
        "label": "By",
        "importPath": "selenium.webdriver.common.by",
        "description": "selenium.webdriver.common.by",
        "isExtraImport": true,
        "detail": "selenium.webdriver.common.by",
        "documentation": {}
    },
    {
        "label": "Options",
        "importPath": "selenium.webdriver.chrome.options",
        "description": "selenium.webdriver.chrome.options",
        "isExtraImport": true,
        "detail": "selenium.webdriver.chrome.options",
        "documentation": {}
    },
    {
        "label": "streamlit",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "streamlit",
        "description": "streamlit",
        "detail": "streamlit",
        "documentation": {}
    },
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "ndcg_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "torch",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch",
        "description": "torch",
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "MSELoss",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "AutoTokenizer",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "AutoModelForSequenceClassification",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "AnalyticsTracker",
        "kind": 6,
        "importPath": "backend.analytics",
        "description": "backend.analytics",
        "peekOfCode": "class AnalyticsTracker:\n    \"\"\"Tracks and logs user interactions for recommendation improvement\"\"\"\n    def __init__(self):\n        self.interactions_file = INTERACTIONS_FILE\n        self.search_log_file = SEARCH_LOG_FILE\n        self.user_stats_file = USER_STATS_FILE\n        # Ensure files exist\n        self.interactions_file.touch(exist_ok=True)\n        self.search_log_file.touch(exist_ok=True)\n        if not self.user_stats_file.exists():",
        "detail": "backend.analytics",
        "documentation": {}
    },
    {
        "label": "get_tracker",
        "kind": 2,
        "importPath": "backend.analytics",
        "description": "backend.analytics",
        "peekOfCode": "def get_tracker() -> AnalyticsTracker:\n    \"\"\"Get global analytics tracker instance\"\"\"\n    global _tracker\n    if _tracker is None:\n        _tracker = AnalyticsTracker()\n    return _tracker\n# Example usage\nif __name__ == \"__main__\":\n    tracker = get_tracker()\n    # Test logging",
        "detail": "backend.analytics",
        "documentation": {}
    },
    {
        "label": "ANALYTICS_DIR",
        "kind": 5,
        "importPath": "backend.analytics",
        "description": "backend.analytics",
        "peekOfCode": "ANALYTICS_DIR = Path(\"analytics_data\")\nANALYTICS_DIR.mkdir(exist_ok=True)\nINTERACTIONS_FILE = ANALYTICS_DIR / \"interactions.jsonl\"  # JSONL for append efficiency\nSEARCH_LOG_FILE = ANALYTICS_DIR / \"search_log.jsonl\"\nUSER_STATS_FILE = ANALYTICS_DIR / \"user_stats.json\"\nclass AnalyticsTracker:\n    \"\"\"Tracks and logs user interactions for recommendation improvement\"\"\"\n    def __init__(self):\n        self.interactions_file = INTERACTIONS_FILE\n        self.search_log_file = SEARCH_LOG_FILE",
        "detail": "backend.analytics",
        "documentation": {}
    },
    {
        "label": "INTERACTIONS_FILE",
        "kind": 5,
        "importPath": "backend.analytics",
        "description": "backend.analytics",
        "peekOfCode": "INTERACTIONS_FILE = ANALYTICS_DIR / \"interactions.jsonl\"  # JSONL for append efficiency\nSEARCH_LOG_FILE = ANALYTICS_DIR / \"search_log.jsonl\"\nUSER_STATS_FILE = ANALYTICS_DIR / \"user_stats.json\"\nclass AnalyticsTracker:\n    \"\"\"Tracks and logs user interactions for recommendation improvement\"\"\"\n    def __init__(self):\n        self.interactions_file = INTERACTIONS_FILE\n        self.search_log_file = SEARCH_LOG_FILE\n        self.user_stats_file = USER_STATS_FILE\n        # Ensure files exist",
        "detail": "backend.analytics",
        "documentation": {}
    },
    {
        "label": "SEARCH_LOG_FILE",
        "kind": 5,
        "importPath": "backend.analytics",
        "description": "backend.analytics",
        "peekOfCode": "SEARCH_LOG_FILE = ANALYTICS_DIR / \"search_log.jsonl\"\nUSER_STATS_FILE = ANALYTICS_DIR / \"user_stats.json\"\nclass AnalyticsTracker:\n    \"\"\"Tracks and logs user interactions for recommendation improvement\"\"\"\n    def __init__(self):\n        self.interactions_file = INTERACTIONS_FILE\n        self.search_log_file = SEARCH_LOG_FILE\n        self.user_stats_file = USER_STATS_FILE\n        # Ensure files exist\n        self.interactions_file.touch(exist_ok=True)",
        "detail": "backend.analytics",
        "documentation": {}
    },
    {
        "label": "USER_STATS_FILE",
        "kind": 5,
        "importPath": "backend.analytics",
        "description": "backend.analytics",
        "peekOfCode": "USER_STATS_FILE = ANALYTICS_DIR / \"user_stats.json\"\nclass AnalyticsTracker:\n    \"\"\"Tracks and logs user interactions for recommendation improvement\"\"\"\n    def __init__(self):\n        self.interactions_file = INTERACTIONS_FILE\n        self.search_log_file = SEARCH_LOG_FILE\n        self.user_stats_file = USER_STATS_FILE\n        # Ensure files exist\n        self.interactions_file.touch(exist_ok=True)\n        self.search_log_file.touch(exist_ok=True)",
        "detail": "backend.analytics",
        "documentation": {}
    },
    {
        "label": "_tracker",
        "kind": 5,
        "importPath": "backend.analytics",
        "description": "backend.analytics",
        "peekOfCode": "_tracker = None\ndef get_tracker() -> AnalyticsTracker:\n    \"\"\"Get global analytics tracker instance\"\"\"\n    global _tracker\n    if _tracker is None:\n        _tracker = AnalyticsTracker()\n    return _tracker\n# Example usage\nif __name__ == \"__main__\":\n    tracker = get_tracker()",
        "detail": "backend.analytics",
        "documentation": {}
    },
    {
        "label": "InteractionRequest",
        "kind": 6,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "class InteractionRequest(BaseModel):\n    user_id: str\n    drama_title: str\n    interaction_type: str\n    search_id: Optional[str] = None\n    position: Optional[int] = None\n    session_id: Optional[str] = None\n@app.post(\"/analytics/interaction\", tags=[\"Analytics\"])\ndef log_interaction(request: InteractionRequest):\n    \"\"\"",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "fuzzy_match_title",
        "kind": 2,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "def fuzzy_match_title(user_input: str, threshold=70):\n    \"\"\"Handle typos and near matches using fuzzy logic.\"\"\"\n    match, score, _ = process.extractOne(user_input, titles, scorer=fuzz.WRatio)\n    if score >= threshold:\n        return match, score\n    return None, score\n@lru_cache(maxsize=128)\ndef cached_encode(text: str):\n    \"\"\"Cached embedding generation for speed.\"\"\"\n    emb = model.encode([text], convert_to_numpy=True)",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "cached_encode",
        "kind": 2,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "def cached_encode(text: str):\n    \"\"\"Cached embedding generation for speed.\"\"\"\n    emb = model.encode([text], convert_to_numpy=True)\n    faiss.normalize_L2(emb)\n    return emb\n# ======================================================\n# STAGE 4 — HYBRID RECOMMENDATION PIPELINE (v4.0 with Phase 1)\n# ======================================================\ndef recommend(\n    title: str,",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "recommend",
        "kind": 2,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "def recommend(\n    title: str,\n    top_n=5,\n    alpha=0.7,  # Will be overridden by dynamic alpha\n    genre=None,\n    director=None,\n    publisher=None,\n    top_rated=False,\n    description=None,\n    rating_value=None,",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "root",
        "kind": 2,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "def root():\n    return {\n        \"message\": \"SeoulMate Kdrama Recommendation API v4.0 Phase 2 is running\",\n        \"phase_1_features\": [\n            \"Query Intent Detection\",\n            \"Dynamic Weight Adjustment\",\n            \"Query Expansion with Synonyms\",\n            \"Click Tracking & Analytics\",\n            \"Auto-Genre Detection\",\n        ],",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "analyze_query",
        "kind": 2,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "def analyze_query(query: str = Query(..., description=\"Query to analyze\")):\n    \"\"\"\n    Analyze a query to detect intent, genres, and other entities.\n    This is a lightweight endpoint for quick analysis without full recommendation.\n    \"\"\"\n    try:\n        analysis = query_analyzer.analyze(query)\n        return {\n            \"query\": query,\n            \"intent\": (",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "get_recommendations",
        "kind": 2,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "def get_recommendations(\n    title: str = Query(..., description=\"Kdrama title or user query\"),\n    top_n: int = Query(5, description=\"Number of recommendations\"),\n    genre: str = Query(None, description=\"Genre filter\"),\n    director: str = Query(None, description=\"Director filter\"),\n    publisher: str = Query(None, description=\"Publisher filter\"),\n    top_rated: bool = Query(False, description=\"Sort by top rating\"),\n    description: str = Query(None, description=\"Description keyword filter\"),\n    rating_value: float = Query(None, description=\"Minimum rating value\"),\n    rating_count: float = Query(None, description=\"Minimum rating count\"),",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "log_interaction",
        "kind": 2,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "def log_interaction(request: InteractionRequest):\n    \"\"\"\n    Log user interaction with a drama\n    Used for:\n    - Click tracking\n    - Implicit feedback\n    - Recommendation improvement\n    \"\"\"\n    try:\n        analytics_tracker.log_interaction(",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "get_popular_dramas",
        "kind": 2,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "def get_popular_dramas(\n    days: int = Query(7, description=\"Look back period in days\"),\n    limit: int = Query(20, description=\"Number of results\"),\n):\n    \"\"\"\n    Get most popular dramas based on user interactions\n    Useful for:\n    - Trending section\n    - Homepage recommendations\n    - Popular now widget",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "get_trending_searches",
        "kind": 2,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "def get_trending_searches(\n    days: int = Query(7, description=\"Look back period in days\"),\n    limit: int = Query(20, description=\"Number of results\"),\n):\n    \"\"\"\n    Get trending search queries\n    Useful for:\n    - Search suggestions\n    - Understanding user interests\n    - Content discovery",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "get_analytics_summary",
        "kind": 2,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "def get_analytics_summary(\n    days: int = Query(7, description=\"Look back period in days\"),\n):\n    \"\"\"\n    Get overall analytics summary\n    Includes:\n    - Total searches\n    - Total interactions\n    - Click-through rate\n    - Unique users",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "get_user_profile",
        "kind": 2,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "def get_user_profile(user_id: str):\n    \"\"\"\n    Get user's taste profile with preferences and statistics\n    Returns:\n    - Genre preferences with scores\n    - Favorite actors and directors\n    - Viewing patterns\n    - User persona labels\n    - Interaction statistics\n    \"\"\"",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "rate_drama",
        "kind": 2,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "def rate_drama(\n    user_id: str,\n    drama_title: str = Query(..., description=\"Title of the drama to rate\"),\n    rating: float = Query(..., ge=0.0, le=10.0, description=\"Rating from 0-10\"),\n):\n    \"\"\"\n    Rate a drama and update user preferences\n    This will:\n    - Update user's genre preferences\n    - Update actor/director preferences",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "reset_user_profile",
        "kind": 2,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "def reset_user_profile(user_id: str):\n    \"\"\"\n    Reset a user's profile (clear all preferences)\n    Use this to:\n    - Start fresh with recommendations\n    - Clear test data\n    - Reset after major preference changes\n    \"\"\"\n    try:\n        profile_manager = get_profile_manager()",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "get_user_statistics",
        "kind": 2,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "def get_user_statistics(user_id: str):\n    \"\"\"\n    Get statistics for a specific user\n    Includes:\n    - Total clicks\n    - Watchlist additions\n    - Interaction history\n    - Preferences\n    \"\"\"\n    try:",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "MODEL_NAME",
        "kind": 5,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "MODEL_NAME = \"paraphrase-multilingual-mpnet-base-v2\"\n# Using fine-tuned cross-encoder trained on K-drama data\nCROSS_ENCODER_MODEL = r\"D:\\Projects\\SeoulMate\\model_traning\\models\\cross-enc-excellent\"\nMODEL_DIR = r\"D:\\Projects\\SeoulMate\\model_traning\\models\"\nINDEX_DIR = r\"D:\\Projects\\SeoulMate\\model_traning\\faiss_index\"\n# ======================================================\n# FASTAPI SETUP\n# ======================================================\napp = FastAPI(\n    title=\"SeoulMate Kdrama Recommendation API\",",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "CROSS_ENCODER_MODEL",
        "kind": 5,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "CROSS_ENCODER_MODEL = r\"D:\\Projects\\SeoulMate\\model_traning\\models\\cross-enc-excellent\"\nMODEL_DIR = r\"D:\\Projects\\SeoulMate\\model_traning\\models\"\nINDEX_DIR = r\"D:\\Projects\\SeoulMate\\model_traning\\faiss_index\"\n# ======================================================\n# FASTAPI SETUP\n# ======================================================\napp = FastAPI(\n    title=\"SeoulMate Kdrama Recommendation API\",\n    version=\"4.0 (Phase 1)\",\n    description=\"Intelligent K-Drama recommendations with AI-powered query understanding and user analytics\",",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "MODEL_DIR",
        "kind": 5,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "MODEL_DIR = r\"D:\\Projects\\SeoulMate\\model_traning\\models\"\nINDEX_DIR = r\"D:\\Projects\\SeoulMate\\model_traning\\faiss_index\"\n# ======================================================\n# FASTAPI SETUP\n# ======================================================\napp = FastAPI(\n    title=\"SeoulMate Kdrama Recommendation API\",\n    version=\"4.0 (Phase 1)\",\n    description=\"Intelligent K-Drama recommendations with AI-powered query understanding and user analytics\",\n)",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "INDEX_DIR",
        "kind": 5,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "INDEX_DIR = r\"D:\\Projects\\SeoulMate\\model_traning\\faiss_index\"\n# ======================================================\n# FASTAPI SETUP\n# ======================================================\napp = FastAPI(\n    title=\"SeoulMate Kdrama Recommendation API\",\n    version=\"4.0 (Phase 1)\",\n    description=\"Intelligent K-Drama recommendations with AI-powered query understanding and user analytics\",\n)\napp.add_middleware(",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "app",
        "kind": 5,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "app = FastAPI(\n    title=\"SeoulMate Kdrama Recommendation API\",\n    version=\"4.0 (Phase 1)\",\n    description=\"Intelligent K-Drama recommendations with AI-powered query understanding and user analytics\",\n)\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],\n    allow_credentials=True,\n    allow_methods=[\"*\"],",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "finetuned_models",
        "kind": 5,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "finetuned_models = (\n    [\n        d\n        for d in os.listdir(MODEL_DIR)\n        if os.path.isdir(os.path.join(MODEL_DIR, d)) and d.startswith(\"sbert-finetuned\")\n    ]\n    if os.path.exists(MODEL_DIR)\n    else []\n)\nif finetuned_models:",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "index",
        "kind": 5,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "index = faiss.read_index(os.path.join(INDEX_DIR, \"index.faiss\"))\nwith open(os.path.join(INDEX_DIR, \"meta.pkl\"), \"rb\") as f:\n    metadata = pickle.load(f)\ntitles = [m[\"Title\"] for m in metadata]\ncorpus = [\n    f\"{m.get('Title', '')} {m.get('Genre', '')} {m.get('Description', '')} {m.get('Cast', '')}\"\n    for m in metadata\n]\n# Using BM25Plus for better performance (improved IDF handling)\nbm25 = BM25Plus([doc.split() for doc in corpus])",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "titles",
        "kind": 5,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "titles = [m[\"Title\"] for m in metadata]\ncorpus = [\n    f\"{m.get('Title', '')} {m.get('Genre', '')} {m.get('Description', '')} {m.get('Cast', '')}\"\n    for m in metadata\n]\n# Using BM25Plus for better performance (improved IDF handling)\nbm25 = BM25Plus([doc.split() for doc in corpus])\nprint(f\"Loaded {len(metadata)} dramas successfully.\")\n# ======================================================\n# STAGE 1.5 — INITIALIZE PHASE 1 ENHANCEMENTS",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "corpus",
        "kind": 5,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "corpus = [\n    f\"{m.get('Title', '')} {m.get('Genre', '')} {m.get('Description', '')} {m.get('Cast', '')}\"\n    for m in metadata\n]\n# Using BM25Plus for better performance (improved IDF handling)\nbm25 = BM25Plus([doc.split() for doc in corpus])\nprint(f\"Loaded {len(metadata)} dramas successfully.\")\n# ======================================================\n# STAGE 1.5 — INITIALIZE PHASE 1 ENHANCEMENTS\n# ======================================================",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "bm25",
        "kind": 5,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "bm25 = BM25Plus([doc.split() for doc in corpus])\nprint(f\"Loaded {len(metadata)} dramas successfully.\")\n# ======================================================\n# STAGE 1.5 — INITIALIZE PHASE 1 ENHANCEMENTS\n# ======================================================\nprint(\"Stage 1.5: Initializing Phase 1 enhancements...\")\nquery_analyzer = QueryAnalyzer()\nanalytics_tracker = get_tracker()\nprint(\"✓ Query analyzer and analytics tracker initialized.\")\n# ======================================================",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "query_analyzer",
        "kind": 5,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "query_analyzer = QueryAnalyzer()\nanalytics_tracker = get_tracker()\nprint(\"✓ Query analyzer and analytics tracker initialized.\")\n# ======================================================\n# STAGE 2 — LOAD OPTIONAL RERANKER\n# ======================================================\ntry:\n    print(\"Stage 2: Loading cross-encoder reranker...\")\n    reranker = CrossEncoder(CROSS_ENCODER_MODEL)\n    use_reranker = True",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "analytics_tracker",
        "kind": 5,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "analytics_tracker = get_tracker()\nprint(\"✓ Query analyzer and analytics tracker initialized.\")\n# ======================================================\n# STAGE 2 — LOAD OPTIONAL RERANKER\n# ======================================================\ntry:\n    print(\"Stage 2: Loading cross-encoder reranker...\")\n    reranker = CrossEncoder(CROSS_ENCODER_MODEL)\n    use_reranker = True\n    print(\"Cross-encoder reranker loaded successfully.\")",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "PersonalizationEngine",
        "kind": 6,
        "importPath": "backend.personalization",
        "description": "backend.personalization",
        "peekOfCode": "class PersonalizationEngine:\n    \"\"\"\n    Applies personalized weighting to recommendation results.\n    Features:\n    - Genre boosting based on user preferences\n    - Actor boosting based on user preferences\n    - Director boosting based on user preferences\n    - Theme matching and boosting\n    - User-specific alpha adjustment\n    \"\"\"",
        "detail": "backend.personalization",
        "documentation": {}
    },
    {
        "label": "get_personalization_engine",
        "kind": 2,
        "importPath": "backend.personalization",
        "description": "backend.personalization",
        "peekOfCode": "def get_personalization_engine() -> PersonalizationEngine:\n    \"\"\"Get global PersonalizationEngine instance\"\"\"\n    global _personalization_engine\n    if _personalization_engine is None:\n        _personalization_engine = PersonalizationEngine()\n    return _personalization_engine",
        "detail": "backend.personalization",
        "documentation": {}
    },
    {
        "label": "_personalization_engine",
        "kind": 5,
        "importPath": "backend.personalization",
        "description": "backend.personalization",
        "peekOfCode": "_personalization_engine = None\ndef get_personalization_engine() -> PersonalizationEngine:\n    \"\"\"Get global PersonalizationEngine instance\"\"\"\n    global _personalization_engine\n    if _personalization_engine is None:\n        _personalization_engine = PersonalizationEngine()\n    return _personalization_engine",
        "detail": "backend.personalization",
        "documentation": {}
    },
    {
        "label": "QueryIntent",
        "kind": 6,
        "importPath": "backend.query_analyzer",
        "description": "backend.query_analyzer",
        "peekOfCode": "class QueryIntent(Enum):\n    \"\"\"Different types of user intents\"\"\"\n    SIMILAR_TO = \"similar_to\"  # \"like Goblin\", \"similar to...\"\n    GENRE_BROWSE = \"genre_browse\"  # \"romance drama\", \"action series\"\n    ACTOR_BASED = \"actor_based\"  # \"Park Seo-joon drama\"\n    TOP_RATED = \"top_rated\"  # \"best drama\", \"top rated\"\n    YEAR_BASED = \"year_based\"  # \"2023 drama\", \"recent shows\"\n    EMOTION_BASED = \"emotion_based\"  # \"sad drama\", \"feel-good\"\n    CONSTRAINT_BASED = \"constraint\"  # \"short drama\", \"under 10 episodes\"\n    TRENDING = \"trending\"  # \"popular now\", \"trending\"",
        "detail": "backend.query_analyzer",
        "documentation": {}
    },
    {
        "label": "QueryAnalyzer",
        "kind": 6,
        "importPath": "backend.query_analyzer",
        "description": "backend.query_analyzer",
        "peekOfCode": "class QueryAnalyzer:\n    \"\"\"Analyzes user queries to extract intent, entities, and expand terms\"\"\"\n    def __init__(self):\n        self.synonyms = SYNONYMS\n        self.intent_patterns = INTENT_PATTERNS\n    def analyze(self, query: str) -> Dict:\n        \"\"\"\n        Main analysis function\n        Returns:\n            {",
        "detail": "backend.query_analyzer",
        "documentation": {}
    },
    {
        "label": "get_search_strategy",
        "kind": 2,
        "importPath": "backend.query_analyzer",
        "description": "backend.query_analyzer",
        "peekOfCode": "def get_search_strategy(intent: QueryIntent) -> Dict:\n    \"\"\"\n    Get recommended search strategy for each intent\n    Returns:\n        {\n            'use_reranker': bool,\n            'top_k_candidates': int,\n            'apply_diversity': bool,\n            'boost_popularity': float\n        }",
        "detail": "backend.query_analyzer",
        "documentation": {}
    },
    {
        "label": "SYNONYMS",
        "kind": 5,
        "importPath": "backend.query_analyzer",
        "description": "backend.query_analyzer",
        "peekOfCode": "SYNONYMS = {\n    # Emotions\n    \"funny\": [\"comedy\", \"humorous\", \"lighthearted\", \"hilarious\", \"witty\"],\n    \"sad\": [\"melodrama\", \"tearjerker\", \"emotional\", \"tragic\", \"touching\"],\n    \"scary\": [\"horror\", \"thriller\", \"suspense\", \"creepy\", \"dark\"],\n    \"happy\": [\"uplifting\", \"cheerful\", \"feel-good\", \"heartwarming\", \"joyful\"],\n    \"romantic\": [\"romance\", \"love story\", \"romantic\", \"sweet\"],\n    \"exciting\": [\"action\", \"thrilling\", \"intense\", \"fast-paced\"],\n    # Time-related\n    \"old\": [\"classic\", \"vintage\", \"retro\", \"90s\", \"2000s\"],",
        "detail": "backend.query_analyzer",
        "documentation": {}
    },
    {
        "label": "INTENT_PATTERNS",
        "kind": 5,
        "importPath": "backend.query_analyzer",
        "description": "backend.query_analyzer",
        "peekOfCode": "INTENT_PATTERNS = {\n    QueryIntent.SIMILAR_TO: [\n        r\"(like|similar to|same as|reminds me of|something like)\\s+(.+)\",\n        r\"(similar|like)\\s+\",\n        r\"more\\s+(of|like)\",\n        r\"anything\\s+like\",\n        r\"shows?\\s+like\",\n    ],\n    QueryIntent.ACTOR_BASED: [\n        r\"(with|starring|featuring|by|acted by|cast)\\s+([A-Z][a-z]+(\\s+[A-Z][a-z]+)+)\",",
        "detail": "backend.query_analyzer",
        "documentation": {}
    },
    {
        "label": "UserProfileManager",
        "kind": 6,
        "importPath": "backend.user_profile",
        "description": "backend.user_profile",
        "peekOfCode": "class UserProfileManager:\n    \"\"\"\n    Manages user profiles and learns preferences from interactions.\n    Features:\n    - Genre preference tracking\n    - Actor preference tracking\n    - Theme preference extraction\n    - Rating pattern analysis\n    - Dynamic profile updating\n    \"\"\"",
        "detail": "backend.user_profile",
        "documentation": {}
    },
    {
        "label": "get_profile_manager",
        "kind": 2,
        "importPath": "backend.user_profile",
        "description": "backend.user_profile",
        "peekOfCode": "def get_profile_manager() -> UserProfileManager:\n    \"\"\"Get global UserProfileManager instance\"\"\"\n    global _profile_manager\n    if _profile_manager is None:\n        _profile_manager = UserProfileManager()\n    return _profile_manager",
        "detail": "backend.user_profile",
        "documentation": {}
    },
    {
        "label": "_profile_manager",
        "kind": 5,
        "importPath": "backend.user_profile",
        "description": "backend.user_profile",
        "peekOfCode": "_profile_manager = None\ndef get_profile_manager() -> UserProfileManager:\n    \"\"\"Get global UserProfileManager instance\"\"\"\n    global _profile_manager\n    if _profile_manager is None:\n        _profile_manager = UserProfileManager()\n    return _profile_manager",
        "detail": "backend.user_profile",
        "documentation": {}
    },
    {
        "label": "sanitize_filename",
        "kind": 2,
        "importPath": "extra.data_scrapper.DramaList_Scrapper.dramaImage",
        "description": "extra.data_scrapper.DramaList_Scrapper.dramaImage",
        "peekOfCode": "def sanitize_filename(name):\n    \"\"\"Remove invalid characters for safe file naming.\"\"\"\n    return re.sub(r'[\\\\/*?:\"<>|]', \"_\", str(name)).strip()\nUSER_AGENTS = [\n    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 \"\n    \"(KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36\",\n    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 13_5_2) AppleWebKit/605.1.15 \"\n    \"(KHTML, like Gecko) Version/17.0 Safari/605.1.15\",\n    \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:126.0) Gecko/20100101 Firefox/126.0\",\n    \"Mozilla/5.0 (Linux; Android 14; SM-S918B) AppleWebKit/537.36 \"",
        "detail": "extra.data_scrapper.DramaList_Scrapper.dramaImage",
        "documentation": {}
    },
    {
        "label": "download_images_from_csv",
        "kind": 2,
        "importPath": "extra.data_scrapper.DramaList_Scrapper.dramaImage",
        "description": "extra.data_scrapper.DramaList_Scrapper.dramaImage",
        "peekOfCode": "def download_images_from_csv(csv_path, output_folder, concurrency=100):\n    \"\"\"Download only missing images from a CSV/Excel file.\"\"\"\n    # Read data\n    if csv_path.lower().endswith(('.xlsx', '.xls')):\n        df = pd.read_excel(csv_path)\n    else:\n        df = pd.read_csv(csv_path, sep=None, engine=\"python\")\n    if \"title\" not in df.columns or \"image\" not in df.columns:\n        raise ValueError(\"The file must contain 'title' and 'image' columns.\")\n    os.makedirs(output_folder, exist_ok=True)",
        "detail": "extra.data_scrapper.DramaList_Scrapper.dramaImage",
        "documentation": {}
    },
    {
        "label": "USER_AGENTS",
        "kind": 5,
        "importPath": "extra.data_scrapper.DramaList_Scrapper.dramaImage",
        "description": "extra.data_scrapper.DramaList_Scrapper.dramaImage",
        "peekOfCode": "USER_AGENTS = [\n    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 \"\n    \"(KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36\",\n    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 13_5_2) AppleWebKit/605.1.15 \"\n    \"(KHTML, like Gecko) Version/17.0 Safari/605.1.15\",\n    \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:126.0) Gecko/20100101 Firefox/126.0\",\n    \"Mozilla/5.0 (Linux; Android 14; SM-S918B) AppleWebKit/537.36 \"\n    \"(KHTML, like Gecko) Chrome/125.0.0.0 Mobile Safari/537.36\",\n    \"Mozilla/5.0 (iPhone; CPU iPhone OS 17_3 like Mac OS X) \"\n    \"AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Mobile/15E148 Safari/604.1\",",
        "detail": "extra.data_scrapper.DramaList_Scrapper.dramaImage",
        "documentation": {}
    },
    {
        "label": "extract_mydramalist_data",
        "kind": 2,
        "importPath": "extra.data_scrapper.DramaList_Scrapper.scrapper",
        "description": "extra.data_scrapper.DramaList_Scrapper.scrapper",
        "peekOfCode": "def extract_mydramalist_data(file_path):\n    \"\"\"Ultra-fast extractor using lxml (no BeautifulSoup).\"\"\"\n    try:\n        with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n            text = f.read()\n    except Exception:\n        return None\n    try:\n        doc = html.fromstring(text)\n    except Exception:",
        "detail": "extra.data_scrapper.DramaList_Scrapper.scrapper",
        "documentation": {}
    },
    {
        "label": "process_folder",
        "kind": 2,
        "importPath": "extra.data_scrapper.DramaList_Scrapper.scrapper",
        "description": "extra.data_scrapper.DramaList_Scrapper.scrapper",
        "peekOfCode": "def process_folder(\n    input_path, output_csv=\"output_fast.csv\", max_workers=None, skip_existing=True\n):\n    \"\"\"Process all HTML files using multithreading and lxml for maximum speed.\"\"\"\n    if not os.path.exists(input_path):\n        print(f\"Path not found: {input_path}\")\n        return\n    # Collect HTML files\n    if os.path.isdir(input_path):\n        files = [",
        "detail": "extra.data_scrapper.DramaList_Scrapper.scrapper",
        "documentation": {}
    },
    {
        "label": "TVSERIES_RE",
        "kind": 5,
        "importPath": "extra.data_scrapper.DramaList_Scrapper.scrapper",
        "description": "extra.data_scrapper.DramaList_Scrapper.scrapper",
        "peekOfCode": "TVSERIES_RE = re.compile(\"TVSeries\")\nDESC_CLASS_RE = re.compile(\n    r\"(show-synopsis|show-synopsis__text|show-details-item__content)\"\n)\ndef extract_mydramalist_data(file_path):\n    \"\"\"Ultra-fast extractor using lxml (no BeautifulSoup).\"\"\"\n    try:\n        with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n            text = f.read()\n    except Exception:",
        "detail": "extra.data_scrapper.DramaList_Scrapper.scrapper",
        "documentation": {}
    },
    {
        "label": "DESC_CLASS_RE",
        "kind": 5,
        "importPath": "extra.data_scrapper.DramaList_Scrapper.scrapper",
        "description": "extra.data_scrapper.DramaList_Scrapper.scrapper",
        "peekOfCode": "DESC_CLASS_RE = re.compile(\n    r\"(show-synopsis|show-synopsis__text|show-details-item__content)\"\n)\ndef extract_mydramalist_data(file_path):\n    \"\"\"Ultra-fast extractor using lxml (no BeautifulSoup).\"\"\"\n    try:\n        with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n            text = f.read()\n    except Exception:\n        return None",
        "detail": "extra.data_scrapper.DramaList_Scrapper.scrapper",
        "documentation": {}
    },
    {
        "label": "remove_emojis",
        "kind": 2,
        "importPath": "extra.data_scrapper.DramaList_Scrapper.scrapper_2",
        "description": "extra.data_scrapper.DramaList_Scrapper.scrapper_2",
        "peekOfCode": "def remove_emojis(text):\n    return re.sub(r\"[\\U00010000-\\U0010ffff]\", \"\", text)\n# -------------------------------------------\n# Download single page\n# -------------------------------------------\nasync def download_page(i, url, context, output_dir, semaphore):\n    url = url.strip()\n    if (\n        not url\n        or url.lower() in [\"n/a\", \"none\", \"null\"]",
        "detail": "extra.data_scrapper.DramaList_Scrapper.scrapper_2",
        "documentation": {}
    },
    {
        "label": "USER_AGENTS",
        "kind": 5,
        "importPath": "extra.data_scrapper.DramaList_Scrapper.scrapper_2",
        "description": "extra.data_scrapper.DramaList_Scrapper.scrapper_2",
        "peekOfCode": "USER_AGENTS = [\n    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36\",\n    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Safari/605.1.15\",\n    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:127.0) Gecko/20100101 Firefox/127.0\",\n    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36\",\n]\n# -------------------------------------------\n# Block unnecessary resources\n# -------------------------------------------\nasync def block_images_and_fonts(route: Route):",
        "detail": "extra.data_scrapper.DramaList_Scrapper.scrapper_2",
        "documentation": {}
    },
    {
        "label": "extract_drama_data_from_html",
        "kind": 2,
        "importPath": "extra.data_scrapper.html_extractor_and_reader",
        "description": "extra.data_scrapper.html_extractor_and_reader",
        "peekOfCode": "def extract_drama_data_from_html(html_content):\n    \"\"\"\n    Extracts drama information from the given HTML content string.\n    Returns a list of dictionaries.\n    \"\"\"\n    soup = BeautifulSoup(html_content, 'html.parser')\n    drama_items = soup.find_all('div', class_='box')\n    extracted_data = []\n    BASE_URL = \"https://mydramalist.com\"\n    for item in drama_items:",
        "detail": "extra.data_scrapper.html_extractor_and_reader",
        "documentation": {}
    },
    {
        "label": "extract_from_folder",
        "kind": 2,
        "importPath": "extra.data_scrapper.html_extractor_and_reader",
        "description": "extra.data_scrapper.html_extractor_and_reader",
        "peekOfCode": "def extract_from_folder(folder_path, output_csv):\n    \"\"\"\n    Loops through all .html files in the given folder,\n    extracts drama data from each file, and saves everything to one CSV.\n    \"\"\"\n    all_data = []\n    for filename in os.listdir(folder_path):\n        if filename.lower().endswith(\".html\"):\n            file_path = os.path.join(folder_path, filename)\n            print(f\"Processing file: {filename}\")",
        "detail": "extra.data_scrapper.html_extractor_and_reader",
        "documentation": {}
    },
    {
        "label": "URL",
        "kind": 5,
        "importPath": "extra.data_scrapper.kissh_extractor",
        "description": "extra.data_scrapper.kissh_extractor",
        "peekOfCode": "URL = \"https://kisskh.co/Explore?status=2&country=2&sub=1&type=1&order=1\"\n# Use a distinct filename for the debug run\nFILENAME = \"kissh_debug_output.html\"\n# Run the asynchronous function\nif __name__ == \"__main__\":\n    asyncio.run(debug_html_fetch_with_playwright(URL, FILENAME))",
        "detail": "extra.data_scrapper.kissh_extractor",
        "documentation": {}
    },
    {
        "label": "FILENAME",
        "kind": 5,
        "importPath": "extra.data_scrapper.kissh_extractor",
        "description": "extra.data_scrapper.kissh_extractor",
        "peekOfCode": "FILENAME = \"kissh_debug_output.html\"\n# Run the asynchronous function\nif __name__ == \"__main__\":\n    asyncio.run(debug_html_fetch_with_playwright(URL, FILENAME))",
        "detail": "extra.data_scrapper.kissh_extractor",
        "documentation": {}
    },
    {
        "label": "remove_refs",
        "kind": 2,
        "importPath": "extra.data_scrapper.wiki_scrapper_playwright",
        "description": "extra.data_scrapper.wiki_scrapper_playwright",
        "peekOfCode": "def remove_refs(text):\n    \"\"\"Remove all reference markers like [1], [ko], [citation needed].\"\"\"\n    return re.sub(r'\\[.*?\\]', '', str(text))\ndef clean_multiline(text):\n    \"\"\"Convert multiline text to properly comma-separated clean string.\"\"\"\n    if not text or str(text).strip().lower() in [\"n/a\", \"na\"]:\n        return \"-\"\n    text = remove_refs(text)\n    parts = re.split(r'[\\n\\r]+', str(text))\n    parts = [p.strip() for p in parts if p.strip()]",
        "detail": "extra.data_scrapper.wiki_scrapper_playwright",
        "documentation": {}
    },
    {
        "label": "clean_multiline",
        "kind": 2,
        "importPath": "extra.data_scrapper.wiki_scrapper_playwright",
        "description": "extra.data_scrapper.wiki_scrapper_playwright",
        "peekOfCode": "def clean_multiline(text):\n    \"\"\"Convert multiline text to properly comma-separated clean string.\"\"\"\n    if not text or str(text).strip().lower() in [\"n/a\", \"na\"]:\n        return \"-\"\n    text = remove_refs(text)\n    parts = re.split(r'[\\n\\r]+', str(text))\n    parts = [p.strip() for p in parts if p.strip()]\n    return \", \".join(parts) if parts else \"-\"\ndef clean_description(desc):\n    \"\"\"Clean [1], etc. and normalize spaces.\"\"\"",
        "detail": "extra.data_scrapper.wiki_scrapper_playwright",
        "documentation": {}
    },
    {
        "label": "clean_description",
        "kind": 2,
        "importPath": "extra.data_scrapper.wiki_scrapper_playwright",
        "description": "extra.data_scrapper.wiki_scrapper_playwright",
        "peekOfCode": "def clean_description(desc):\n    \"\"\"Clean [1], etc. and normalize spaces.\"\"\"\n    if not desc:\n        return \"-\"\n    desc = remove_refs(desc)\n    desc = re.sub(r'\\s+', ' ', desc).strip()\n    return desc if desc else \"-\"\ndef extract_years_from_release(text):\n    \"\"\"Extract release year(s) from release date text.\"\"\"\n    if not text or str(text).strip().lower() in [\"n/a\", \"na\", \"-\"]:",
        "detail": "extra.data_scrapper.wiki_scrapper_playwright",
        "documentation": {}
    },
    {
        "label": "extract_years_from_release",
        "kind": 2,
        "importPath": "extra.data_scrapper.wiki_scrapper_playwright",
        "description": "extra.data_scrapper.wiki_scrapper_playwright",
        "peekOfCode": "def extract_years_from_release(text):\n    \"\"\"Extract release year(s) from release date text.\"\"\"\n    if not text or str(text).strip().lower() in [\"n/a\", \"na\", \"-\"]:\n        return \"-\"\n    text = remove_refs(text)\n    full_years = re.findall(r'(?:19|20)\\d{2}', text)\n    unique_years = list(dict.fromkeys(full_years))  # preserve order\n    return \", \".join(unique_years) if unique_years else \"-\"\n# =========================================================\n# Fallback: Description method",
        "detail": "extra.data_scrapper.wiki_scrapper_playwright",
        "documentation": {}
    },
    {
        "label": "get_description_fallback",
        "kind": 2,
        "importPath": "extra.data_scrapper.wiki_scrapper_playwright",
        "description": "extra.data_scrapper.wiki_scrapper_playwright",
        "peekOfCode": "def get_description_fallback(url):\n    headers = {\n        \"User-Agent\": (\n            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n            \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n            \"Chrome/118.0.0.0 Safari/537.36\"\n        )\n    }\n    try:\n        response = requests.get(url, headers=headers, timeout=10)",
        "detail": "extra.data_scrapper.wiki_scrapper_playwright",
        "documentation": {}
    },
    {
        "label": "remove_refs",
        "kind": 2,
        "importPath": "extra.data_scrapper.wiki_scrapper_selenium",
        "description": "extra.data_scrapper.wiki_scrapper_selenium",
        "peekOfCode": "def remove_refs(text):\n    \"\"\"Remove all reference markers like [1], [ko], [citation needed].\"\"\"\n    return re.sub(r'\\[.*?\\]', '', str(text))\ndef clean_multiline(text):\n    \"\"\"Convert multiline text to properly comma-separated clean string.\"\"\"\n    if not text or str(text).strip().lower() in [\"n/a\", \"na\"]:\n        return \"-\"\n    text = remove_refs(text)\n    parts = re.split(r'[\\n\\r]+', str(text))\n    parts = [p.strip() for p in parts if p.strip()]",
        "detail": "extra.data_scrapper.wiki_scrapper_selenium",
        "documentation": {}
    },
    {
        "label": "clean_multiline",
        "kind": 2,
        "importPath": "extra.data_scrapper.wiki_scrapper_selenium",
        "description": "extra.data_scrapper.wiki_scrapper_selenium",
        "peekOfCode": "def clean_multiline(text):\n    \"\"\"Convert multiline text to properly comma-separated clean string.\"\"\"\n    if not text or str(text).strip().lower() in [\"n/a\", \"na\"]:\n        return \"-\"\n    text = remove_refs(text)\n    parts = re.split(r'[\\n\\r]+', str(text))\n    parts = [p.strip() for p in parts if p.strip()]\n    return \", \".join(parts) if parts else \"-\"\ndef clean_description(desc):\n    \"\"\"Clean [1], etc. and normalize spaces.\"\"\"",
        "detail": "extra.data_scrapper.wiki_scrapper_selenium",
        "documentation": {}
    },
    {
        "label": "clean_description",
        "kind": 2,
        "importPath": "extra.data_scrapper.wiki_scrapper_selenium",
        "description": "extra.data_scrapper.wiki_scrapper_selenium",
        "peekOfCode": "def clean_description(desc):\n    \"\"\"Clean [1], etc. and normalize spaces.\"\"\"\n    if not desc:\n        return \"-\"\n    desc = remove_refs(desc)\n    desc = re.sub(r'\\s+', ' ', desc).strip()\n    return desc if desc else \"-\"\ndef extract_years_from_release(text):\n    \"\"\"Extract release year(s) from release date text.\"\"\"\n    if not text or str(text).strip().lower() in [\"n/a\", \"na\", \"-\"]:",
        "detail": "extra.data_scrapper.wiki_scrapper_selenium",
        "documentation": {}
    },
    {
        "label": "extract_years_from_release",
        "kind": 2,
        "importPath": "extra.data_scrapper.wiki_scrapper_selenium",
        "description": "extra.data_scrapper.wiki_scrapper_selenium",
        "peekOfCode": "def extract_years_from_release(text):\n    \"\"\"Extract release year(s) from release date text.\"\"\"\n    if not text or str(text).strip().lower() in [\"n/a\", \"na\", \"-\"]:\n        return \"-\"\n    text = remove_refs(text)\n    # Match 4-digit years (e.g., 2004, 2015, 2020)\n    years = re.findall(r'(19|20)\\d{2}', text)\n    # Join unique years (sorted in order of appearance)\n    if not years:\n        return \"-\"",
        "detail": "extra.data_scrapper.wiki_scrapper_selenium",
        "documentation": {}
    },
    {
        "label": "get_description_fallback",
        "kind": 2,
        "importPath": "extra.data_scrapper.wiki_scrapper_selenium",
        "description": "extra.data_scrapper.wiki_scrapper_selenium",
        "peekOfCode": "def get_description_fallback(url):\n    headers = {\n        \"User-Agent\": (\n            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n            \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n            \"Chrome/118.0.0.0 Safari/537.36\"\n        )\n    }\n    try:\n        response = requests.get(url, headers=headers, timeout=10)",
        "detail": "extra.data_scrapper.wiki_scrapper_selenium",
        "documentation": {}
    },
    {
        "label": "chrome_options",
        "kind": 5,
        "importPath": "extra.data_scrapper.wiki_scrapper_selenium",
        "description": "extra.data_scrapper.wiki_scrapper_selenium",
        "peekOfCode": "chrome_options = Options()\nchrome_options.add_argument(\"--headless\")\nchrome_options.add_argument(\"--no-sandbox\")\nchrome_options.add_argument(\"--disable-dev-shm-usage\")\ndriver = webdriver.Chrome(options=chrome_options)\n# ---------------------------\n# Wikipedia main list\n# ---------------------------\nbase_url = \"https://en.wikipedia.org/wiki/List_of_South_Korean_dramas\"\ndriver.get(base_url)",
        "detail": "extra.data_scrapper.wiki_scrapper_selenium",
        "documentation": {}
    },
    {
        "label": "driver",
        "kind": 5,
        "importPath": "extra.data_scrapper.wiki_scrapper_selenium",
        "description": "extra.data_scrapper.wiki_scrapper_selenium",
        "peekOfCode": "driver = webdriver.Chrome(options=chrome_options)\n# ---------------------------\n# Wikipedia main list\n# ---------------------------\nbase_url = \"https://en.wikipedia.org/wiki/List_of_South_Korean_dramas\"\ndriver.get(base_url)\ntime.sleep(3)\n# ---------------------------\n# Collect all drama links\n# ---------------------------",
        "detail": "extra.data_scrapper.wiki_scrapper_selenium",
        "documentation": {}
    },
    {
        "label": "base_url",
        "kind": 5,
        "importPath": "extra.data_scrapper.wiki_scrapper_selenium",
        "description": "extra.data_scrapper.wiki_scrapper_selenium",
        "peekOfCode": "base_url = \"https://en.wikipedia.org/wiki/List_of_South_Korean_dramas\"\ndriver.get(base_url)\ntime.sleep(3)\n# ---------------------------\n# Collect all drama links\n# ---------------------------\nprint(\"Collecting drama links...\")\ndrama_links = []\nelems = driver.find_elements(By.CLASS_NAME, \"div-col\")\nfor elem in elems:",
        "detail": "extra.data_scrapper.wiki_scrapper_selenium",
        "documentation": {}
    },
    {
        "label": "drama_links",
        "kind": 5,
        "importPath": "extra.data_scrapper.wiki_scrapper_selenium",
        "description": "extra.data_scrapper.wiki_scrapper_selenium",
        "peekOfCode": "drama_links = []\nelems = driver.find_elements(By.CLASS_NAME, \"div-col\")\nfor elem in elems:\n    links = elem.find_elements(By.CSS_SELECTOR, \"a[href]\")\n    for link in links:\n        href = link.get_attribute(\"href\")\n        if href and \"wiki\" in href and \"redlink\" not in href:\n            drama_links.append(href)\ndrama_links = list(set(drama_links))\nprint(f\"Found {len(drama_links)} drama links\")",
        "detail": "extra.data_scrapper.wiki_scrapper_selenium",
        "documentation": {}
    },
    {
        "label": "elems",
        "kind": 5,
        "importPath": "extra.data_scrapper.wiki_scrapper_selenium",
        "description": "extra.data_scrapper.wiki_scrapper_selenium",
        "peekOfCode": "elems = driver.find_elements(By.CLASS_NAME, \"div-col\")\nfor elem in elems:\n    links = elem.find_elements(By.CSS_SELECTOR, \"a[href]\")\n    for link in links:\n        href = link.get_attribute(\"href\")\n        if href and \"wiki\" in href and \"redlink\" not in href:\n            drama_links.append(href)\ndrama_links = list(set(drama_links))\nprint(f\"Found {len(drama_links)} drama links\")\n# ---------------------------",
        "detail": "extra.data_scrapper.wiki_scrapper_selenium",
        "documentation": {}
    },
    {
        "label": "drama_links",
        "kind": 5,
        "importPath": "extra.data_scrapper.wiki_scrapper_selenium",
        "description": "extra.data_scrapper.wiki_scrapper_selenium",
        "peekOfCode": "drama_links = list(set(drama_links))\nprint(f\"Found {len(drama_links)} drama links\")\n# ---------------------------\n# Scrape each drama page\n# ---------------------------\ntitles, alt_titles, writers, directors, casts, genres, networks, episodes, releases, release_years, posters, descriptions = [], [], [], [], [], [], [], [], [], [], [], []\nfor i, url in enumerate(drama_links):  # you can limit with [:10] for testing\n    print(f\"\\nScraping ({i+1}/{len(drama_links)}): {url}\")\n    driver.get(url)\n    time.sleep(1.5)",
        "detail": "extra.data_scrapper.wiki_scrapper_selenium",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "extra.data_scrapper.wiki_scrapper_selenium",
        "description": "extra.data_scrapper.wiki_scrapper_selenium",
        "peekOfCode": "df = pd.DataFrame({\n    \"Title\": titles,\n    \"Also Known As\": alt_titles,\n    \"Written By\": writers,\n    \"Director\": directors,\n    \"Cast\": casts,\n    \"Genre\": genres,\n    \"Network\": networks,\n    \"Episodes\": episodes,\n    \"Release Dates\": releases,",
        "detail": "extra.data_scrapper.wiki_scrapper_selenium",
        "documentation": {}
    },
    {
        "label": "check_api_health",
        "kind": 2,
        "importPath": "frontend.streamlit_app",
        "description": "frontend.streamlit_app",
        "peekOfCode": "def check_api_health() -> bool:\n    \"\"\"Check if backend API is running\"\"\"\n    try:\n        response = requests.get(f\"{API_URL}/\", timeout=2)\n        return response.status_code == 200\n    except Exception:\n        return False\ndef log_interaction(drama_title: str, interaction_type: str, position: int = None):\n    \"\"\"Log user interaction (click, watchlist_add, watchlist_remove) to backend\"\"\"\n    try:",
        "detail": "frontend.streamlit_app",
        "documentation": {}
    },
    {
        "label": "log_interaction",
        "kind": 2,
        "importPath": "frontend.streamlit_app",
        "description": "frontend.streamlit_app",
        "peekOfCode": "def log_interaction(drama_title: str, interaction_type: str, position: int = None):\n    \"\"\"Log user interaction (click, watchlist_add, watchlist_remove) to backend\"\"\"\n    try:\n        payload = {\n            \"user_id\": st.session_state.user_id,\n            \"session_id\": st.session_state.session_id,\n            \"search_id\": st.session_state.last_search_id,\n            \"drama_title\": drama_title,\n            \"interaction_type\": interaction_type,\n            \"position\": position,",
        "detail": "frontend.streamlit_app",
        "documentation": {}
    },
    {
        "label": "get_recommendations",
        "kind": 2,
        "importPath": "frontend.streamlit_app",
        "description": "frontend.streamlit_app",
        "peekOfCode": "def get_recommendations(query: str, top_n: int = 5, **filters) -> Dict:\n    \"\"\"Get recommendations from backend API with analytics tracking\"\"\"\n    try:\n        params = {\n            \"title\": query,\n            \"top_n\": top_n,\n            \"user_id\": st.session_state.user_id,\n            \"session_id\": st.session_state.session_id,\n        }\n        params.update(filters)",
        "detail": "frontend.streamlit_app",
        "documentation": {}
    },
    {
        "label": "format_drama_card",
        "kind": 2,
        "importPath": "frontend.streamlit_app",
        "description": "frontend.streamlit_app",
        "peekOfCode": "def format_drama_card(drama: Dict, rank: int) -> str:\n    \"\"\"Format drama data into interactive HTML card with click tracking\"\"\"\n    title = drama.get(\"Title\", \"Unknown\")\n    genre = drama.get(\"Genre\", drama.get(\"genres\", \"N/A\"))\n    description = drama.get(\n        \"Description\", drama.get(\"description\", \"No description available\")\n    )\n    # Truncate description\n    if len(description) > 250:\n        description = description[:250] + \"...\"",
        "detail": "frontend.streamlit_app",
        "documentation": {}
    },
    {
        "label": "API_URL",
        "kind": 5,
        "importPath": "frontend.streamlit_app",
        "description": "frontend.streamlit_app",
        "peekOfCode": "API_URL = \"http://127.0.0.1:8001\"\n# ======================================================\n# SESSION STATE INITIALIZATION\n# ======================================================\nif \"user_id\" not in st.session_state:\n    st.session_state.user_id = f\"user_{uuid.uuid4().hex[:8]}\"\nif \"session_id\" not in st.session_state:\n    st.session_state.session_id = f\"session_{time.time()}\"\nif \"last_search_id\" not in st.session_state:\n    st.session_state.last_search_id = None",
        "detail": "frontend.streamlit_app",
        "documentation": {}
    },
    {
        "label": "clean_text",
        "kind": 2,
        "importPath": "model_traning.build_index",
        "description": "model_traning.build_index",
        "peekOfCode": "def clean_text(text):\n    return \" \".join(str(text).replace(\"\\n\", \" \").replace(\"\\r\", \" \").split())\nfor col in df.columns:\n    df[col] = df[col].astype(str).apply(clean_text)\n# Create unified text field for embeddings\ntext_features = [\n    \"Title\",\n    \"Genre\",\n    \"Description\",\n    \"Cast\",",
        "detail": "model_traning.build_index",
        "documentation": {}
    },
    {
        "label": "DATA_PATH",
        "kind": 5,
        "importPath": "model_traning.build_index",
        "description": "model_traning.build_index",
        "peekOfCode": "DATA_PATH = r\"D:\\Projects\\SeoulMate\\dataset\\dramalist_kdramas.xlsx\"\nMODEL_NAME = \"paraphrase-multilingual-mpnet-base-v2\"\nMODEL_DIR = r\"D:\\Projects\\SeoulMate\\model_traning\\models\"\nINDEX_DIR = r\"D:\\Projects\\SeoulMate\\model_traning\\faiss_index\"\nos.makedirs(MODEL_DIR, exist_ok=True)\nos.makedirs(INDEX_DIR, exist_ok=True)\n# If you've fine-tuned a local SBERT model, save it to MODEL_DIR/sbert-finetuned*\n# The script will prefer any local fine-tuned model automatically when present.\nFINETUNED_PREFIX = \"sbert-finetuned\"\n# ======================================================",
        "detail": "model_traning.build_index",
        "documentation": {}
    },
    {
        "label": "MODEL_NAME",
        "kind": 5,
        "importPath": "model_traning.build_index",
        "description": "model_traning.build_index",
        "peekOfCode": "MODEL_NAME = \"paraphrase-multilingual-mpnet-base-v2\"\nMODEL_DIR = r\"D:\\Projects\\SeoulMate\\model_traning\\models\"\nINDEX_DIR = r\"D:\\Projects\\SeoulMate\\model_traning\\faiss_index\"\nos.makedirs(MODEL_DIR, exist_ok=True)\nos.makedirs(INDEX_DIR, exist_ok=True)\n# If you've fine-tuned a local SBERT model, save it to MODEL_DIR/sbert-finetuned*\n# The script will prefer any local fine-tuned model automatically when present.\nFINETUNED_PREFIX = \"sbert-finetuned\"\n# ======================================================\n# 2. Load and Prepare Dataset",
        "detail": "model_traning.build_index",
        "documentation": {}
    },
    {
        "label": "MODEL_DIR",
        "kind": 5,
        "importPath": "model_traning.build_index",
        "description": "model_traning.build_index",
        "peekOfCode": "MODEL_DIR = r\"D:\\Projects\\SeoulMate\\model_traning\\models\"\nINDEX_DIR = r\"D:\\Projects\\SeoulMate\\model_traning\\faiss_index\"\nos.makedirs(MODEL_DIR, exist_ok=True)\nos.makedirs(INDEX_DIR, exist_ok=True)\n# If you've fine-tuned a local SBERT model, save it to MODEL_DIR/sbert-finetuned*\n# The script will prefer any local fine-tuned model automatically when present.\nFINETUNED_PREFIX = \"sbert-finetuned\"\n# ======================================================\n# 2. Load and Prepare Dataset\n# ======================================================",
        "detail": "model_traning.build_index",
        "documentation": {}
    },
    {
        "label": "INDEX_DIR",
        "kind": 5,
        "importPath": "model_traning.build_index",
        "description": "model_traning.build_index",
        "peekOfCode": "INDEX_DIR = r\"D:\\Projects\\SeoulMate\\model_traning\\faiss_index\"\nos.makedirs(MODEL_DIR, exist_ok=True)\nos.makedirs(INDEX_DIR, exist_ok=True)\n# If you've fine-tuned a local SBERT model, save it to MODEL_DIR/sbert-finetuned*\n# The script will prefer any local fine-tuned model automatically when present.\nFINETUNED_PREFIX = \"sbert-finetuned\"\n# ======================================================\n# 2. Load and Prepare Dataset\n# ======================================================\nprint(\"Loading dataset...\")",
        "detail": "model_traning.build_index",
        "documentation": {}
    },
    {
        "label": "FINETUNED_PREFIX",
        "kind": 5,
        "importPath": "model_traning.build_index",
        "description": "model_traning.build_index",
        "peekOfCode": "FINETUNED_PREFIX = \"sbert-finetuned\"\n# ======================================================\n# 2. Load and Prepare Dataset\n# ======================================================\nprint(\"Loading dataset...\")\ndf = pd.read_excel(DATA_PATH)\ndf.fillna(\"\", inplace=True)\n# Map column names to standardized format\ncolumn_mapping = {\n    \"title\": \"Title\",",
        "detail": "model_traning.build_index",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "model_traning.build_index",
        "description": "model_traning.build_index",
        "peekOfCode": "df = pd.read_excel(DATA_PATH)\ndf.fillna(\"\", inplace=True)\n# Map column names to standardized format\ncolumn_mapping = {\n    \"title\": \"Title\",\n    \"genres\": \"Genre\",\n    \"description\": \"Description\",\n    \"actors\": \"Cast\",\n    \"directors\": \"Director\",\n    \"alternate_names\": \"Also Known As\",",
        "detail": "model_traning.build_index",
        "documentation": {}
    },
    {
        "label": "column_mapping",
        "kind": 5,
        "importPath": "model_traning.build_index",
        "description": "model_traning.build_index",
        "peekOfCode": "column_mapping = {\n    \"title\": \"Title\",\n    \"genres\": \"Genre\",\n    \"description\": \"Description\",\n    \"actors\": \"Cast\",\n    \"directors\": \"Director\",\n    \"alternate_names\": \"Also Known As\",\n    \"publisher\": \"Network\",\n    \"aired\": \"Release Years\",\n}",
        "detail": "model_traning.build_index",
        "documentation": {}
    },
    {
        "label": "text_features",
        "kind": 5,
        "importPath": "model_traning.build_index",
        "description": "model_traning.build_index",
        "peekOfCode": "text_features = [\n    \"Title\",\n    \"Genre\",\n    \"Description\",\n    \"Cast\",\n    \"Director\",\n    \"Also Known As\",\n    \"Network\",\n    \"Release Years\",\n    \"keywords\",",
        "detail": "model_traning.build_index",
        "documentation": {}
    },
    {
        "label": "available_features",
        "kind": 5,
        "importPath": "model_traning.build_index",
        "description": "model_traning.build_index",
        "peekOfCode": "available_features = [col for col in text_features if col in df.columns]\ndf[\"content\"] = df[available_features].astype(str).agg(\" \".join, axis=1)\n# ======================================================\n# 3. Load SentenceTransformer Model\n# ======================================================\nprint(\"Loading SentenceTransformer model...\")\n# Look for any local fine-tuned folder starting with 'sbert-finetuned'\n# Prefer 'sbert-finetuned-full' if exists, else use most recent\nselected_local = None\ntry:",
        "detail": "model_traning.build_index",
        "documentation": {}
    },
    {
        "label": "df[\"content\"]",
        "kind": 5,
        "importPath": "model_traning.build_index",
        "description": "model_traning.build_index",
        "peekOfCode": "df[\"content\"] = df[available_features].astype(str).agg(\" \".join, axis=1)\n# ======================================================\n# 3. Load SentenceTransformer Model\n# ======================================================\nprint(\"Loading SentenceTransformer model...\")\n# Look for any local fine-tuned folder starting with 'sbert-finetuned'\n# Prefer 'sbert-finetuned-full' if exists, else use most recent\nselected_local = None\ntry:\n    candidates = [",
        "detail": "model_traning.build_index",
        "documentation": {}
    },
    {
        "label": "selected_local",
        "kind": 5,
        "importPath": "model_traning.build_index",
        "description": "model_traning.build_index",
        "peekOfCode": "selected_local = None\ntry:\n    candidates = [\n        name\n        for name in os.listdir(MODEL_DIR)\n        if name.startswith(FINETUNED_PREFIX)\n        and os.path.isdir(os.path.join(MODEL_DIR, name))\n    ]\n    if candidates:\n        # Prefer 'sbert-finetuned-full' if available",
        "detail": "model_traning.build_index",
        "documentation": {}
    },
    {
        "label": "batch_size",
        "kind": 5,
        "importPath": "model_traning.build_index",
        "description": "model_traning.build_index",
        "peekOfCode": "batch_size = 16\nembeddings = model.encode(\n    df[\"content\"].tolist(),\n    show_progress_bar=True,\n    convert_to_numpy=True,\n    batch_size=batch_size,\n)\n# ======================================================\n# 5. Build FAISS Index\n# ======================================================",
        "detail": "model_traning.build_index",
        "documentation": {}
    },
    {
        "label": "embeddings",
        "kind": 5,
        "importPath": "model_traning.build_index",
        "description": "model_traning.build_index",
        "peekOfCode": "embeddings = model.encode(\n    df[\"content\"].tolist(),\n    show_progress_bar=True,\n    convert_to_numpy=True,\n    batch_size=batch_size,\n)\n# ======================================================\n# 5. Build FAISS Index\n# ======================================================\ndim = embeddings.shape[1]",
        "detail": "model_traning.build_index",
        "documentation": {}
    },
    {
        "label": "dim",
        "kind": 5,
        "importPath": "model_traning.build_index",
        "description": "model_traning.build_index",
        "peekOfCode": "dim = embeddings.shape[1]\nindex = faiss.IndexFlatIP(dim)  # Inner product for cosine similarity\nfaiss.normalize_L2(embeddings)\nindex.add(embeddings)\nprint(f\"FAISS index built successfully with {index.ntotal} items.\")\n# ======================================================\n# 6. Save Index and Metadata\n# ======================================================\nfaiss.write_index(index, os.path.join(INDEX_DIR, \"index.faiss\"))\n# Save relevant metadata (keep it clean for inference)",
        "detail": "model_traning.build_index",
        "documentation": {}
    },
    {
        "label": "index",
        "kind": 5,
        "importPath": "model_traning.build_index",
        "description": "model_traning.build_index",
        "peekOfCode": "index = faiss.IndexFlatIP(dim)  # Inner product for cosine similarity\nfaiss.normalize_L2(embeddings)\nindex.add(embeddings)\nprint(f\"FAISS index built successfully with {index.ntotal} items.\")\n# ======================================================\n# 6. Save Index and Metadata\n# ======================================================\nfaiss.write_index(index, os.path.join(INDEX_DIR, \"index.faiss\"))\n# Save relevant metadata (keep it clean for inference)\nmeta_cols = [",
        "detail": "model_traning.build_index",
        "documentation": {}
    },
    {
        "label": "meta_cols",
        "kind": 5,
        "importPath": "model_traning.build_index",
        "description": "model_traning.build_index",
        "peekOfCode": "meta_cols = [\n    \"Title\",\n    \"Genre\",\n    \"Description\",\n    \"Cast\",\n    \"Director\",\n    \"Network\",\n    \"Release Years\",\n    \"Also Known As\",\n    \"rating_value\",",
        "detail": "model_traning.build_index",
        "documentation": {}
    },
    {
        "label": "meta_cols",
        "kind": 5,
        "importPath": "model_traning.build_index",
        "description": "model_traning.build_index",
        "peekOfCode": "meta_cols = [c for c in meta_cols if c in df.columns]\nmetadata = df[meta_cols].to_dict(orient=\"records\")\nwith open(os.path.join(INDEX_DIR, \"meta.pkl\"), \"wb\") as f:\n    pickle.dump(metadata, f)\nprint(f\"Index and metadata saved in: {INDEX_DIR}\")\nprint(\"All done! Your FAISS index is ready for recommendations.\")",
        "detail": "model_traning.build_index",
        "documentation": {}
    },
    {
        "label": "metadata",
        "kind": 5,
        "importPath": "model_traning.build_index",
        "description": "model_traning.build_index",
        "peekOfCode": "metadata = df[meta_cols].to_dict(orient=\"records\")\nwith open(os.path.join(INDEX_DIR, \"meta.pkl\"), \"wb\") as f:\n    pickle.dump(metadata, f)\nprint(f\"Index and metadata saved in: {INDEX_DIR}\")\nprint(\"All done! Your FAISS index is ready for recommendations.\")",
        "detail": "model_traning.build_index",
        "documentation": {}
    },
    {
        "label": "load_metadata",
        "kind": 2,
        "importPath": "model_traning.eval_retrieval",
        "description": "model_traning.eval_retrieval",
        "peekOfCode": "def load_metadata(meta_path):\n    with open(meta_path, \"rb\") as f:\n        return pickle.load(f)\ndef build_default_testset(metadata, n=100):\n    queries = []\n    true_ids = []\n    for i, m in enumerate(metadata[:n]):\n        title = m.get(\"Title\") or m.get(\"title\") or \"\"\n        if not title:\n            continue",
        "detail": "model_traning.eval_retrieval",
        "documentation": {}
    },
    {
        "label": "build_default_testset",
        "kind": 2,
        "importPath": "model_traning.eval_retrieval",
        "description": "model_traning.eval_retrieval",
        "peekOfCode": "def build_default_testset(metadata, n=100):\n    queries = []\n    true_ids = []\n    for i, m in enumerate(metadata[:n]):\n        title = m.get(\"Title\") or m.get(\"title\") or \"\"\n        if not title:\n            continue\n        queries.append(title)\n        true_ids.append(i)\n    return queries, true_ids",
        "detail": "model_traning.eval_retrieval",
        "documentation": {}
    },
    {
        "label": "read_csv_testset",
        "kind": 2,
        "importPath": "model_traning.eval_retrieval",
        "description": "model_traning.eval_retrieval",
        "peekOfCode": "def read_csv_testset(path):\n    queries = []\n    true_ids = []\n    with open(path, encoding=\"utf-8-sig\") as f:\n        reader = csv.DictReader(f)\n        for r in reader:\n            queries.append(r[\"query\"])\n            true_ids.append(int(r[\"true_id\"]))\n    return queries, true_ids\ndef recall_at_k(I, true_ids, k):",
        "detail": "model_traning.eval_retrieval",
        "documentation": {}
    },
    {
        "label": "recall_at_k",
        "kind": 2,
        "importPath": "model_traning.eval_retrieval",
        "description": "model_traning.eval_retrieval",
        "peekOfCode": "def recall_at_k(I, true_ids, k):\n    hits = 0\n    for ids, t in zip(I, true_ids):\n        hits += int(t in ids[:k])\n    return hits / len(true_ids)\ndef ndcg_at_k(I, D, true_ids, k):\n    # Build per-query y_true (one-hot over returned candidates) and scores\n    y_true = []\n    y_score = []\n    for ids, scores, t in zip(I, D, true_ids):",
        "detail": "model_traning.eval_retrieval",
        "documentation": {}
    },
    {
        "label": "ndcg_at_k",
        "kind": 2,
        "importPath": "model_traning.eval_retrieval",
        "description": "model_traning.eval_retrieval",
        "peekOfCode": "def ndcg_at_k(I, D, true_ids, k):\n    # Build per-query y_true (one-hot over returned candidates) and scores\n    y_true = []\n    y_score = []\n    for ids, scores, t in zip(I, D, true_ids):\n        topk_ids = ids[:k]\n        rel = [1 if tid == t else 0 for tid in topk_ids]\n        y_true.append(rel)\n        y_score.append(scores[:k])\n    # sklearn expects arrays",
        "detail": "model_traning.eval_retrieval",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "model_traning.eval_retrieval",
        "description": "model_traning.eval_retrieval",
        "peekOfCode": "def main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        \"--model\", default=None, help=\"Path to SBERT model (folder) or HF model name\"\n    )\n    parser.add_argument(\n        \"--index\",\n        default=r\"d:\\Projects\\SeoulMate\\model_traning\\faiss_index\\index.faiss\",\n    )\n    parser.add_argument(",
        "detail": "model_traning.eval_retrieval",
        "documentation": {}
    },
    {
        "label": "PairDataset",
        "kind": 6,
        "importPath": "model_traning.fine_tune_cross_encoder",
        "description": "model_traning.fine_tune_cross_encoder",
        "peekOfCode": "class PairDataset(Dataset):\n    def __init__(self, rows: List[Dict]):\n        self.rows = rows\n    def __len__(self):\n        return len(self.rows)\n    def __getitem__(self, idx):\n        r = self.rows[idx]\n        return r[\"query\"], r[\"doc_text\"], float(r[\"label\"])\ndef collate_fn(batch, tokenizer, max_length=256):\n    queries, docs, labels = zip(*batch)",
        "detail": "model_traning.fine_tune_cross_encoder",
        "documentation": {}
    },
    {
        "label": "collate_fn",
        "kind": 2,
        "importPath": "model_traning.fine_tune_cross_encoder",
        "description": "model_traning.fine_tune_cross_encoder",
        "peekOfCode": "def collate_fn(batch, tokenizer, max_length=256):\n    queries, docs, labels = zip(*batch)\n    # tokenizer supports encoding pairs: (query, doc)\n    enc = tokenizer(\n        list(queries),\n        list(docs),\n        padding=True,\n        truncation=True,\n        max_length=max_length,\n        return_tensors=\"pt\",",
        "detail": "model_traning.fine_tune_cross_encoder",
        "documentation": {}
    },
    {
        "label": "read_csv",
        "kind": 2,
        "importPath": "model_traning.fine_tune_cross_encoder",
        "description": "model_traning.fine_tune_cross_encoder",
        "peekOfCode": "def read_csv(path):\n    rows = []\n    with open(path, encoding=\"utf-8-sig\") as f:\n        reader = csv.DictReader(f)\n        for r in reader:\n            if \"query\" not in r or \"doc_text\" not in r or \"label\" not in r:\n                continue\n            rows.append(\n                {\n                    \"query\": r[\"query\"],",
        "detail": "model_traning.fine_tune_cross_encoder",
        "documentation": {}
    },
    {
        "label": "train",
        "kind": 2,
        "importPath": "model_traning.fine_tune_cross_encoder",
        "description": "model_traning.fine_tune_cross_encoder",
        "peekOfCode": "def train(args):\n    assert os.path.exists(args.data), f\"Data file not found: {args.data}\"\n    rows = read_csv(args.data)\n    if len(rows) == 0:\n        raise SystemExit(\"No training rows found in CSV\")\n    # optionally limit for quick CPU runs\n    if args.max_examples and args.max_examples > 0:\n        rows = rows[: args.max_examples]\n    tokenizer = AutoTokenizer.from_pretrained(args.model)\n    model = AutoModelForSequenceClassification.from_pretrained(args.model, num_labels=1)",
        "detail": "model_traning.fine_tune_cross_encoder",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "model_traning.fine_tune_cross_encoder",
        "description": "model_traning.fine_tune_cross_encoder",
        "peekOfCode": "def main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        \"--data\", required=True, help=\"CSV with columns query,doc_text,label\"\n    )\n    parser.add_argument(\"--model\", default=\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n    parser.add_argument(\"--output\", default=\"models/cross-enc-finetuned\")\n    parser.add_argument(\"--epochs\", type=int, default=1)\n    parser.add_argument(\"--batch_size\", type=int, default=8)\n    parser.add_argument(\"--lr\", type=float, default=2e-5)",
        "detail": "model_traning.fine_tune_cross_encoder",
        "documentation": {}
    },
    {
        "label": "build_examples",
        "kind": 2,
        "importPath": "model_traning.fine_tune_sbert",
        "description": "model_traning.fine_tune_sbert",
        "peekOfCode": "def build_examples(df, max_examples=None):\n    examples = []\n    for _, row in df.iterrows():\n        title = str(row.get(\"title\") or row.get(\"Title\") or \"\")\n        # Build a content string with relevant fields\n        parts = []\n        for c in [\n            \"title\",\n            \"Title\",\n            \"genres\",",
        "detail": "model_traning.fine_tune_sbert",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "model_traning.fine_tune_sbert",
        "description": "model_traning.fine_tune_sbert",
        "peekOfCode": "def main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--data\", required=True, help=\"Path to dataset (csv or xlsx)\")\n    parser.add_argument(\"--model\", default=\"paraphrase-multilingual-mpnet-base-v2\")\n    parser.add_argument(\n        \"--output\", required=True, help=\"Output folder to save fine-tuned model\"\n    )\n    parser.add_argument(\"--batch_size\", type=int, default=16)\n    parser.add_argument(\"--epochs\", type=int, default=1)\n    parser.add_argument(",
        "detail": "model_traning.fine_tune_sbert",
        "documentation": {}
    },
    {
        "label": "load_metadata",
        "kind": 2,
        "importPath": "model_traning.generate_reranker_data",
        "description": "model_traning.generate_reranker_data",
        "peekOfCode": "def load_metadata(meta_path):\n    with open(meta_path, \"rb\") as f:\n        return pickle.load(f)\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        \"--index\",\n        default=r\"d:\\Projects\\SeoulMate\\model_traning\\faiss_index\\index.faiss\",\n    )\n    parser.add_argument(",
        "detail": "model_traning.generate_reranker_data",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "model_traning.generate_reranker_data",
        "description": "model_traning.generate_reranker_data",
        "peekOfCode": "def main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        \"--index\",\n        default=r\"d:\\Projects\\SeoulMate\\model_traning\\faiss_index\\index.faiss\",\n    )\n    parser.add_argument(\n        \"--meta\", default=r\"d:\\Projects\\SeoulMate\\model_traning\\faiss_index\\meta.pkl\"\n    )\n    parser.add_argument(",
        "detail": "model_traning.generate_reranker_data",
        "documentation": {}
    },
    {
        "label": "historical_count",
        "kind": 5,
        "importPath": "tests.check_genres",
        "description": "tests.check_genres",
        "peekOfCode": "historical_count = 0\nfor m in meta:\n    genre_str = str(m.get(\"Genre\", \"\")) + str(m.get(\"genres\", \"\"))\n    if \"historical\" in genre_str.lower():\n        historical_count += 1\n        if historical_count <= 5:\n            print(f\"{historical_count}. {m['Title']}\")\n            print(f\"   Genre: {m.get('Genre', 'N/A')}\")\n            print(f\"   genres: {m.get('genres', 'N/A')}\")\n            print()",
        "detail": "tests.check_genres",
        "documentation": {}
    },
    {
        "label": "metadata_path",
        "kind": 5,
        "importPath": "tests.check_genres_2",
        "description": "tests.check_genres_2",
        "peekOfCode": "metadata_path = None\npossible_paths = [\n    \"../model_traning/faiss_index/meta.pkl\",\n    \"./meta.pkl\",\n    \"faiss_index/meta.pkl\",\n    \"d:/Projects/SeoulMate/model_traning/faiss_index/meta.pkl\",\n]\nfor path in possible_paths:\n    if os.path.exists(path):\n        metadata_path = path",
        "detail": "tests.check_genres_2",
        "documentation": {}
    },
    {
        "label": "possible_paths",
        "kind": 5,
        "importPath": "tests.check_genres_2",
        "description": "tests.check_genres_2",
        "peekOfCode": "possible_paths = [\n    \"../model_traning/faiss_index/meta.pkl\",\n    \"./meta.pkl\",\n    \"faiss_index/meta.pkl\",\n    \"d:/Projects/SeoulMate/model_traning/faiss_index/meta.pkl\",\n]\nfor path in possible_paths:\n    if os.path.exists(path):\n        metadata_path = path\n        break",
        "detail": "tests.check_genres_2",
        "documentation": {}
    },
    {
        "label": "medical_count",
        "kind": 5,
        "importPath": "tests.check_genres_2",
        "description": "tests.check_genres_2",
        "peekOfCode": "medical_count = 0\nfor drama in metadata:\n    title = drama.get(\"Title\", drama.get(\"title\", \"Unknown\"))\n    genre = str(drama.get(\"Genre\", drama.get(\"genres\", \"\")))\n    if (\n        \"medical\" in genre.lower()\n        or \"doctor\" in genre.lower()\n        or \"hospital\" in genre.lower()\n    ):\n        medical_count += 1",
        "detail": "tests.check_genres_2",
        "documentation": {}
    },
    {
        "label": "API_URL",
        "kind": 5,
        "importPath": "tests.test_all_genres",
        "description": "tests.test_all_genres",
        "peekOfCode": "API_URL = \"http://127.0.0.1:8001\"\nprint(\"=\" * 80)\nprint(\"GENRE FILTER FIX - COMPREHENSIVE TEST\")\nprint(\"=\" * 80)\ntests = [\n    {\n        \"name\": \"TEST 1: Historical dramas (with genre filter)\",\n        \"params\": {\"title\": \"historical\", \"genre\": \"Historical\", \"top_n\": 5},\n        \"expected\": \"Should return ONLY historical dramas\",\n    },",
        "detail": "tests.test_all_genres",
        "documentation": {}
    },
    {
        "label": "tests",
        "kind": 5,
        "importPath": "tests.test_all_genres",
        "description": "tests.test_all_genres",
        "peekOfCode": "tests = [\n    {\n        \"name\": \"TEST 1: Historical dramas (with genre filter)\",\n        \"params\": {\"title\": \"historical\", \"genre\": \"Historical\", \"top_n\": 5},\n        \"expected\": \"Should return ONLY historical dramas\",\n    },\n    {\n        \"name\": \"TEST 2: Romance dramas (with genre filter)\",\n        \"params\": {\"title\": \"romance\", \"genre\": \"Romance\", \"top_n\": 5},\n        \"expected\": \"Should return ONLY romance dramas\",",
        "detail": "tests.test_all_genres",
        "documentation": {}
    },
    {
        "label": "analyzer",
        "kind": 5,
        "importPath": "tests.test_analysis",
        "description": "tests.test_analysis",
        "peekOfCode": "analyzer = QueryAnalyzer()\n# Test various medical queries\ntest_queries = [\n    \"medical drama\",\n    \"a medical drama\",\n    \"medical kdrama\",\n    \"medical korean drama\",\n    \"action thriller\",\n    \"historical drama\",\n    \"school romance\",",
        "detail": "tests.test_analysis",
        "documentation": {}
    },
    {
        "label": "test_queries",
        "kind": 5,
        "importPath": "tests.test_analysis",
        "description": "tests.test_analysis",
        "peekOfCode": "test_queries = [\n    \"medical drama\",\n    \"a medical drama\",\n    \"medical kdrama\",\n    \"medical korean drama\",\n    \"action thriller\",\n    \"historical drama\",\n    \"school romance\",\n]\nprint(\"Testing Query Analysis:\")",
        "detail": "tests.test_analysis",
        "documentation": {}
    },
    {
        "label": "test_api_health",
        "kind": 2,
        "importPath": "tests.test_api",
        "description": "tests.test_api",
        "peekOfCode": "def test_api_health():\n    \"\"\"Test if API is running\"\"\"\n    try:\n        response = requests.get(f\"{API_URL}/\")\n        print(\"✅ API Health Check:\", response.json())\n        return True\n    except Exception as e:\n        print(\"❌ API not reachable:\", str(e))\n        return False\ndef test_recommendation(title, top_n=5):",
        "detail": "tests.test_api",
        "documentation": {}
    },
    {
        "label": "test_recommendation",
        "kind": 2,
        "importPath": "tests.test_api",
        "description": "tests.test_api",
        "peekOfCode": "def test_recommendation(title, top_n=5):\n    \"\"\"Test recommendation endpoint\"\"\"\n    print(f\"\\n🔍 Getting recommendations for: '{title}'\")\n    print(f\"   Requesting top {top_n} dramas...\\n\")\n    try:\n        response = requests.get(\n            f\"{API_URL}/recommend\", params={\"title\": title, \"top_n\": top_n}\n        )\n        if response.status_code == 200:\n            data = response.json()",
        "detail": "tests.test_api",
        "documentation": {}
    },
    {
        "label": "run_tests",
        "kind": 2,
        "importPath": "tests.test_api",
        "description": "tests.test_api",
        "peekOfCode": "def run_tests():\n    \"\"\"Run all tests\"\"\"\n    print(\"=\" * 60)\n    print(\"🎬 SeoulMate K-Drama Recommendation API Test Suite\")\n    print(\"=\" * 60)\n    # Test 1: Health check\n    if not test_api_health():\n        print(\"\\n⚠️  Start the backend server first:\")\n        print(\"   cd d:\\\\Projects\\\\SeoulMate\\\\backend\")\n        print(\"   python app.py\")",
        "detail": "tests.test_api",
        "documentation": {}
    },
    {
        "label": "API_URL",
        "kind": 5,
        "importPath": "tests.test_api",
        "description": "tests.test_api",
        "peekOfCode": "API_URL = \"http://127.0.0.1:8001\"\ndef test_api_health():\n    \"\"\"Test if API is running\"\"\"\n    try:\n        response = requests.get(f\"{API_URL}/\")\n        print(\"✅ API Health Check:\", response.json())\n        return True\n    except Exception as e:\n        print(\"❌ API not reachable:\", str(e))\n        return False",
        "detail": "tests.test_api",
        "documentation": {}
    },
    {
        "label": "API_URL",
        "kind": 5,
        "importPath": "tests.test_complete_flow",
        "description": "tests.test_complete_flow",
        "peekOfCode": "API_URL = \"http://127.0.0.1:8001\"\ntest_queries = [\n    \"medical drama\",\n    \"a medical drama\",\n    \"medical kdrama\",\n    \"historical drama\",\n    \"action thriller\",\n    \"school romance\",\n]\nprint(\"Testing Complete Flow: Analyze -> Detect Genre -> Filter\")",
        "detail": "tests.test_complete_flow",
        "documentation": {}
    },
    {
        "label": "test_queries",
        "kind": 5,
        "importPath": "tests.test_complete_flow",
        "description": "tests.test_complete_flow",
        "peekOfCode": "test_queries = [\n    \"medical drama\",\n    \"a medical drama\",\n    \"medical kdrama\",\n    \"historical drama\",\n    \"action thriller\",\n    \"school romance\",\n]\nprint(\"Testing Complete Flow: Analyze -> Detect Genre -> Filter\")\nprint(\"=\" * 80)",
        "detail": "tests.test_complete_flow",
        "documentation": {}
    },
    {
        "label": "metadata_path",
        "kind": 5,
        "importPath": "tests.test_filter",
        "description": "tests.test_filter",
        "peekOfCode": "metadata_path = \"../model_traning/faiss_index/meta.pkl\"\nwith open(metadata_path, \"rb\") as f:\n    metadata = pickle.load(f)\nprint(\"=\" * 80)\nprint(\"TESTING GENRE FILTER LOGIC\")\nprint(\"=\" * 80)\n# Test the filter logic used in app.py\ngenre_to_test = \"Medical\"\nprint(f\"\\nTesting filter for genre: '{genre_to_test}'\")\nprint(\"-\" * 80)",
        "detail": "tests.test_filter",
        "documentation": {}
    },
    {
        "label": "genre_to_test",
        "kind": 5,
        "importPath": "tests.test_filter",
        "description": "tests.test_filter",
        "peekOfCode": "genre_to_test = \"Medical\"\nprint(f\"\\nTesting filter for genre: '{genre_to_test}'\")\nprint(\"-\" * 80)\nfiltered = [\n    r\n    for r in metadata\n    if genre_to_test.lower() in str(r.get(\"Genre\", \"\")).lower()\n    or genre_to_test.lower() in str(r.get(\"genres\", \"\")).lower()\n]\nprint(f\"✓ Found {len(filtered)} dramas with '{genre_to_test}' genre\")",
        "detail": "tests.test_filter",
        "documentation": {}
    },
    {
        "label": "filtered",
        "kind": 5,
        "importPath": "tests.test_filter",
        "description": "tests.test_filter",
        "peekOfCode": "filtered = [\n    r\n    for r in metadata\n    if genre_to_test.lower() in str(r.get(\"Genre\", \"\")).lower()\n    or genre_to_test.lower() in str(r.get(\"genres\", \"\")).lower()\n]\nprint(f\"✓ Found {len(filtered)} dramas with '{genre_to_test}' genre\")\nprint(\"\\nFirst 10 results:\")\nfor i, drama in enumerate(filtered[:10], 1):\n    title = drama.get(\"Title\", \"Unknown\")",
        "detail": "tests.test_filter",
        "documentation": {}
    },
    {
        "label": "query",
        "kind": 5,
        "importPath": "tests.test_filter",
        "description": "tests.test_filter",
        "peekOfCode": "query = \"medical drama\"\ndetected_genre = \"Medical\"  # This is what query_analyzer detects\nprint(f\"\\nUser searches: '{query}'\")\nprint(f\"Query analyzer detects genre: '{detected_genre}'\")\nprint(f\"Backend applies filter: genre.lower() in Genre.lower()\")\n# Apply the filter\nfiltered_metadata = [\n    r for r in metadata if detected_genre.lower() in str(r.get(\"Genre\", \"\")).lower()\n]\nprint(f\"\\n✓ Filter applied successfully\")",
        "detail": "tests.test_filter",
        "documentation": {}
    },
    {
        "label": "detected_genre",
        "kind": 5,
        "importPath": "tests.test_filter",
        "description": "tests.test_filter",
        "peekOfCode": "detected_genre = \"Medical\"  # This is what query_analyzer detects\nprint(f\"\\nUser searches: '{query}'\")\nprint(f\"Query analyzer detects genre: '{detected_genre}'\")\nprint(f\"Backend applies filter: genre.lower() in Genre.lower()\")\n# Apply the filter\nfiltered_metadata = [\n    r for r in metadata if detected_genre.lower() in str(r.get(\"Genre\", \"\")).lower()\n]\nprint(f\"\\n✓ Filter applied successfully\")\nprint(f\"✓ Result: {len(filtered_metadata)} medical dramas found\")",
        "detail": "tests.test_filter",
        "documentation": {}
    },
    {
        "label": "filtered_metadata",
        "kind": 5,
        "importPath": "tests.test_filter",
        "description": "tests.test_filter",
        "peekOfCode": "filtered_metadata = [\n    r for r in metadata if detected_genre.lower() in str(r.get(\"Genre\", \"\")).lower()\n]\nprint(f\"\\n✓ Filter applied successfully\")\nprint(f\"✓ Result: {len(filtered_metadata)} medical dramas found\")\nif len(filtered_metadata) > 0:\n    print(\"\\n✅ FILTER IS WORKING!\")\n    print(\"Top 5 results would be:\")\n    for i, drama in enumerate(filtered_metadata[:5], 1):\n        print(f\"  {i}. {drama.get('Title')}\")",
        "detail": "tests.test_filter",
        "documentation": {}
    },
    {
        "label": "analyzer",
        "kind": 5,
        "importPath": "tests.test_genre_detection",
        "description": "tests.test_genre_detection",
        "peekOfCode": "analyzer = QueryAnalyzer()\n# Test queries\ntest_queries = [\n    \"medical drama\",\n    \"historical drama\",\n    \"action thriller\",\n    \"school drama\",\n    \"office romance\",\n    \"sports anime\",\n    \"medical series\",",
        "detail": "tests.test_genre_detection",
        "documentation": {}
    },
    {
        "label": "test_queries",
        "kind": 5,
        "importPath": "tests.test_genre_detection",
        "description": "tests.test_genre_detection",
        "peekOfCode": "test_queries = [\n    \"medical drama\",\n    \"historical drama\",\n    \"action thriller\",\n    \"school drama\",\n    \"office romance\",\n    \"sports anime\",\n    \"medical series\",\n    \"historical period drama\",\n    \"romantic comedy\",",
        "detail": "tests.test_genre_detection",
        "documentation": {}
    },
    {
        "label": "response",
        "kind": 5,
        "importPath": "tests.test_genre_filter",
        "description": "tests.test_genre_filter",
        "peekOfCode": "response = requests.get(\n    \"http://127.0.0.1:8001/recommend\",\n    params={\"title\": \"drama\", \"genre\": \"Historical\", \"top_n\": 5},\n)\nresults = response.json()\nprint(f\"\\nQuery: {results['query']}\")\nprint(f\"Filters: {results['filters']}\")\nprint(f\"\\nRecommendations ({len(results['recommendations'])}):\")\nfor i, rec in enumerate(results[\"recommendations\"], 1):\n    print(f\"\\n{i}. {rec['Title']}\")",
        "detail": "tests.test_genre_filter",
        "documentation": {}
    },
    {
        "label": "results",
        "kind": 5,
        "importPath": "tests.test_genre_filter",
        "description": "tests.test_genre_filter",
        "peekOfCode": "results = response.json()\nprint(f\"\\nQuery: {results['query']}\")\nprint(f\"Filters: {results['filters']}\")\nprint(f\"\\nRecommendations ({len(results['recommendations'])}):\")\nfor i, rec in enumerate(results[\"recommendations\"], 1):\n    print(f\"\\n{i}. {rec['Title']}\")\n    print(f\"   Genre: {rec.get('Genre', 'N/A')}\")\n# Test 2: Just search \"historical drama\" without filter\nprint(\"\\n\" + \"=\" * 80)\nprint(\"TEST 2: Searching 'historical drama' WITHOUT genre filter (like the button)\")",
        "detail": "tests.test_genre_filter",
        "documentation": {}
    },
    {
        "label": "response",
        "kind": 5,
        "importPath": "tests.test_genre_filter",
        "description": "tests.test_genre_filter",
        "peekOfCode": "response = requests.get(\n    \"http://127.0.0.1:8001/recommend\", params={\"title\": \"historical drama\", \"top_n\": 5}\n)\nresults = response.json()\nprint(f\"\\nQuery: {results['query']}\")\nprint(f\"Filters: {results['filters']}\")\nprint(f\"\\nRecommendations ({len(results['recommendations'])}):\")\nfor i, rec in enumerate(results[\"recommendations\"], 1):\n    print(f\"\\n{i}. {rec['Title']}\")\n    print(f\"   Genre: {rec.get('Genre', 'N/A')}\")",
        "detail": "tests.test_genre_filter",
        "documentation": {}
    },
    {
        "label": "results",
        "kind": 5,
        "importPath": "tests.test_genre_filter",
        "description": "tests.test_genre_filter",
        "peekOfCode": "results = response.json()\nprint(f\"\\nQuery: {results['query']}\")\nprint(f\"Filters: {results['filters']}\")\nprint(f\"\\nRecommendations ({len(results['recommendations'])}):\")\nfor i, rec in enumerate(results[\"recommendations\"], 1):\n    print(f\"\\n{i}. {rec['Title']}\")\n    print(f\"   Genre: {rec.get('Genre', 'N/A')}\")",
        "detail": "tests.test_genre_filter",
        "documentation": {}
    },
    {
        "label": "response",
        "kind": 5,
        "importPath": "tests.test_historical",
        "description": "tests.test_historical",
        "peekOfCode": "response = requests.get(\n    \"http://127.0.0.1:8001/recommend\",\n    params={\"title\": \"historical\", \"genre\": \"Historical\", \"top_n\": 5},\n)\nresults = response.json()\nprint(f\"\\nQuery: {results['query']}\")\nprint(f\"Filters: {results['filters']}\")\nprint(f\"\\nRecommendations ({len(results['recommendations'])}):\")\nfor i, rec in enumerate(results[\"recommendations\"], 1):\n    print(f\"\\n{i}. {rec['Title']}\")",
        "detail": "tests.test_historical",
        "documentation": {}
    },
    {
        "label": "results",
        "kind": 5,
        "importPath": "tests.test_historical",
        "description": "tests.test_historical",
        "peekOfCode": "results = response.json()\nprint(f\"\\nQuery: {results['query']}\")\nprint(f\"Filters: {results['filters']}\")\nprint(f\"\\nRecommendations ({len(results['recommendations'])}):\")\nfor i, rec in enumerate(results[\"recommendations\"], 1):\n    print(f\"\\n{i}. {rec['Title']}\")\n    print(f\"   Genre: {rec.get('Genre', 'N/A')}\")\n    print(f\"   Rating: {rec.get('rating_value', 'N/A')}\")",
        "detail": "tests.test_historical",
        "documentation": {}
    },
    {
        "label": "profile_manager",
        "kind": 5,
        "importPath": "tests.test_personalization",
        "description": "tests.test_personalization",
        "peekOfCode": "profile_manager = UserProfileManager(profiles_dir=\"../tests/test_profiles\")\npersonalization_engine = PersonalizationEngine()\n# Test 1: Create two users with different preferences\nprint(\"\\n1️⃣ Creating two users with different preferences...\")\n# Medical Drama Fan\nmedical_user = \"medical_fan\"\nmedical_dramas = [\n    {\n        \"Title\": \"Hospital Playlist\",\n        \"Genre\": \"Medical, Life\",",
        "detail": "tests.test_personalization",
        "documentation": {}
    },
    {
        "label": "personalization_engine",
        "kind": 5,
        "importPath": "tests.test_personalization",
        "description": "tests.test_personalization",
        "peekOfCode": "personalization_engine = PersonalizationEngine()\n# Test 1: Create two users with different preferences\nprint(\"\\n1️⃣ Creating two users with different preferences...\")\n# Medical Drama Fan\nmedical_user = \"medical_fan\"\nmedical_dramas = [\n    {\n        \"Title\": \"Hospital Playlist\",\n        \"Genre\": \"Medical, Life\",\n        \"Cast\": \"Jo Jung-suk, Yoo Yeon-seok\",",
        "detail": "tests.test_personalization",
        "documentation": {}
    },
    {
        "label": "medical_user",
        "kind": 5,
        "importPath": "tests.test_personalization",
        "description": "tests.test_personalization",
        "peekOfCode": "medical_user = \"medical_fan\"\nmedical_dramas = [\n    {\n        \"Title\": \"Hospital Playlist\",\n        \"Genre\": \"Medical, Life\",\n        \"Cast\": \"Jo Jung-suk, Yoo Yeon-seok\",\n        \"Director\": \"Shin Won-ho\",\n    },\n    {\n        \"Title\": \"Good Doctor\",",
        "detail": "tests.test_personalization",
        "documentation": {}
    },
    {
        "label": "medical_dramas",
        "kind": 5,
        "importPath": "tests.test_personalization",
        "description": "tests.test_personalization",
        "peekOfCode": "medical_dramas = [\n    {\n        \"Title\": \"Hospital Playlist\",\n        \"Genre\": \"Medical, Life\",\n        \"Cast\": \"Jo Jung-suk, Yoo Yeon-seok\",\n        \"Director\": \"Shin Won-ho\",\n    },\n    {\n        \"Title\": \"Good Doctor\",\n        \"Genre\": \"Medical\",",
        "detail": "tests.test_personalization",
        "documentation": {}
    },
    {
        "label": "thriller_user",
        "kind": 5,
        "importPath": "tests.test_personalization",
        "description": "tests.test_personalization",
        "peekOfCode": "thriller_user = \"thriller_fan\"\nthriller_dramas = [\n    {\n        \"Title\": \"Signal\",\n        \"Genre\": \"Thriller, Mystery\",\n        \"Cast\": \"Lee Je-hoon, Kim Hye-soo\",\n        \"Director\": \"Kim Won-seok\",\n    },\n    {\n        \"Title\": \"Stranger\",",
        "detail": "tests.test_personalization",
        "documentation": {}
    },
    {
        "label": "thriller_dramas",
        "kind": 5,
        "importPath": "tests.test_personalization",
        "description": "tests.test_personalization",
        "peekOfCode": "thriller_dramas = [\n    {\n        \"Title\": \"Signal\",\n        \"Genre\": \"Thriller, Mystery\",\n        \"Cast\": \"Lee Je-hoon, Kim Hye-soo\",\n        \"Director\": \"Kim Won-seok\",\n    },\n    {\n        \"Title\": \"Stranger\",\n        \"Genre\": \"Thriller, Crime\",",
        "detail": "tests.test_personalization",
        "documentation": {}
    },
    {
        "label": "mock_results",
        "kind": 5,
        "importPath": "tests.test_personalization",
        "description": "tests.test_personalization",
        "peekOfCode": "mock_results = [\n    {\n        \"Title\": \"Doctor John\",\n        \"Genre\": \"Medical, Romance\",\n        \"Cast\": \"Ji Sung, Lee Se-young\",\n        \"Director\": \"Jo Soo-won\",\n        \"score\": 0.75,\n    },\n    {\n        \"Title\": \"Flower of Evil\",",
        "detail": "tests.test_personalization",
        "documentation": {}
    },
    {
        "label": "medical_profile",
        "kind": 5,
        "importPath": "tests.test_personalization",
        "description": "tests.test_personalization",
        "peekOfCode": "medical_profile = profile_manager.load_profile(medical_user)\nmedical_results = personalization_engine.personalize_results(\n    mock_results.copy(), medical_profile, apply_boosting=True\n)\nprint(\"   Results for Medical fan:\")\nfor i, drama in enumerate(medical_results[:3], 1):\n    boost = drama.get(\"boost_multiplier\", 1.0)\n    base = drama.get(\"base_score\", 0)\n    pers = drama.get(\"personalized_score\", 0)\n    print(f\"      {i}. {drama['Title']}\")",
        "detail": "tests.test_personalization",
        "documentation": {}
    },
    {
        "label": "medical_results",
        "kind": 5,
        "importPath": "tests.test_personalization",
        "description": "tests.test_personalization",
        "peekOfCode": "medical_results = personalization_engine.personalize_results(\n    mock_results.copy(), medical_profile, apply_boosting=True\n)\nprint(\"   Results for Medical fan:\")\nfor i, drama in enumerate(medical_results[:3], 1):\n    boost = drama.get(\"boost_multiplier\", 1.0)\n    base = drama.get(\"base_score\", 0)\n    pers = drama.get(\"personalized_score\", 0)\n    print(f\"      {i}. {drama['Title']}\")\n    print(f\"         Genre: {drama['Genre']}\")",
        "detail": "tests.test_personalization",
        "documentation": {}
    },
    {
        "label": "thriller_profile",
        "kind": 5,
        "importPath": "tests.test_personalization",
        "description": "tests.test_personalization",
        "peekOfCode": "thriller_profile = profile_manager.load_profile(thriller_user)\nthriller_results = personalization_engine.personalize_results(\n    mock_results.copy(), thriller_profile, apply_boosting=True\n)\nprint(\"   Results for Thriller fan:\")\nfor i, drama in enumerate(thriller_results[:3], 1):\n    boost = drama.get(\"boost_multiplier\", 1.0)\n    base = drama.get(\"base_score\", 0)\n    pers = drama.get(\"personalized_score\", 0)\n    print(f\"      {i}. {drama['Title']}\")",
        "detail": "tests.test_personalization",
        "documentation": {}
    },
    {
        "label": "thriller_results",
        "kind": 5,
        "importPath": "tests.test_personalization",
        "description": "tests.test_personalization",
        "peekOfCode": "thriller_results = personalization_engine.personalize_results(\n    mock_results.copy(), thriller_profile, apply_boosting=True\n)\nprint(\"   Results for Thriller fan:\")\nfor i, drama in enumerate(thriller_results[:3], 1):\n    boost = drama.get(\"boost_multiplier\", 1.0)\n    base = drama.get(\"base_score\", 0)\n    pers = drama.get(\"personalized_score\", 0)\n    print(f\"      {i}. {drama['Title']}\")\n    print(f\"         Genre: {drama['Genre']}\")",
        "detail": "tests.test_personalization",
        "documentation": {}
    },
    {
        "label": "medical_top",
        "kind": 5,
        "importPath": "tests.test_personalization",
        "description": "tests.test_personalization",
        "peekOfCode": "medical_top = medical_results[0][\"Title\"]\nthriller_top = thriller_results[0][\"Title\"]\nprint(f\"   Medical fan's #1 recommendation: {medical_top}\")\nprint(f\"   Thriller fan's #1 recommendation: {thriller_top}\")\nif medical_top != thriller_top:\n    print(\"   ✅ SUCCESS: Different users get different recommendations!\")\nelse:\n    print(\"   ⚠️  Warning: Both users got same top recommendation\")\n# Test 6: Test personalization summaries\nprint(\"\\n6️⃣ Testing personalization summaries...\")",
        "detail": "tests.test_personalization",
        "documentation": {}
    },
    {
        "label": "thriller_top",
        "kind": 5,
        "importPath": "tests.test_personalization",
        "description": "tests.test_personalization",
        "peekOfCode": "thriller_top = thriller_results[0][\"Title\"]\nprint(f\"   Medical fan's #1 recommendation: {medical_top}\")\nprint(f\"   Thriller fan's #1 recommendation: {thriller_top}\")\nif medical_top != thriller_top:\n    print(\"   ✅ SUCCESS: Different users get different recommendations!\")\nelse:\n    print(\"   ⚠️  Warning: Both users got same top recommendation\")\n# Test 6: Test personalization summaries\nprint(\"\\n6️⃣ Testing personalization summaries...\")\nfor drama in medical_results[:2]:",
        "detail": "tests.test_personalization",
        "documentation": {}
    },
    {
        "label": "base_alpha",
        "kind": 5,
        "importPath": "tests.test_personalization",
        "description": "tests.test_personalization",
        "peekOfCode": "base_alpha = 0.7\nmedical_alpha = personalization_engine.calculate_user_specific_alpha(\n    medical_profile, base_alpha\n)\nthriller_alpha = personalization_engine.calculate_user_specific_alpha(\n    thriller_profile, base_alpha\n)\nprint(f\"   Base alpha: {base_alpha:.2f}\")\nprint(f\"   Medical fan alpha: {medical_alpha:.2f}\")\nprint(f\"   Thriller fan alpha: {thriller_alpha:.2f}\")",
        "detail": "tests.test_personalization",
        "documentation": {}
    },
    {
        "label": "medical_alpha",
        "kind": 5,
        "importPath": "tests.test_personalization",
        "description": "tests.test_personalization",
        "peekOfCode": "medical_alpha = personalization_engine.calculate_user_specific_alpha(\n    medical_profile, base_alpha\n)\nthriller_alpha = personalization_engine.calculate_user_specific_alpha(\n    thriller_profile, base_alpha\n)\nprint(f\"   Base alpha: {base_alpha:.2f}\")\nprint(f\"   Medical fan alpha: {medical_alpha:.2f}\")\nprint(f\"   Thriller fan alpha: {thriller_alpha:.2f}\")\nprint(\"\\n\" + \"=\" * 80)",
        "detail": "tests.test_personalization",
        "documentation": {}
    },
    {
        "label": "thriller_alpha",
        "kind": 5,
        "importPath": "tests.test_personalization",
        "description": "tests.test_personalization",
        "peekOfCode": "thriller_alpha = personalization_engine.calculate_user_specific_alpha(\n    thriller_profile, base_alpha\n)\nprint(f\"   Base alpha: {base_alpha:.2f}\")\nprint(f\"   Medical fan alpha: {medical_alpha:.2f}\")\nprint(f\"   Thriller fan alpha: {thriller_alpha:.2f}\")\nprint(\"\\n\" + \"=\" * 80)\nprint(\"✅ Personalized Weighting Tests Complete!\")\nprint(\"=\" * 80)\nprint(\"\\n📊 Summary:\")",
        "detail": "tests.test_personalization",
        "documentation": {}
    },
    {
        "label": "test_query_intent",
        "kind": 2,
        "importPath": "tests.test_phase1",
        "description": "tests.test_phase1",
        "peekOfCode": "def test_query_intent():\n    \"\"\"Test query intent detection and dynamic weights\"\"\"\n    print(\"\\n📝 TEST 1: Query Intent Detection & Dynamic Weights\")\n    print(\"-\" * 80)\n    test_queries = [\n        (\"romantic comedy\", \"genre_browse\"),\n        (\"something like Goblin\", \"similar_to\"),\n        (\"Park Seo-joon drama\", \"actor_based\"),\n        (\"best 2023 drama\", \"top_rated\"),\n        (\"sad emotional drama\", \"emotion_based\"),",
        "detail": "tests.test_phase1",
        "documentation": {}
    },
    {
        "label": "test_query_expansion",
        "kind": 2,
        "importPath": "tests.test_phase1",
        "description": "tests.test_phase1",
        "peekOfCode": "def test_query_expansion():\n    \"\"\"Test query expansion with synonyms\"\"\"\n    print(\"\\n\\n📚 TEST 2: Query Expansion\")\n    print(\"-\" * 80)\n    test_cases = [\"funny drama\", \"sad romance\", \"scary thriller\", \"old classic drama\"]\n    for query in test_cases:\n        try:\n            response = requests.get(\n                f\"{BASE_URL}/recommend\", params={\"title\": query, \"top_n\": 2}, timeout=10\n            )",
        "detail": "tests.test_phase1",
        "documentation": {}
    },
    {
        "label": "test_click_tracking",
        "kind": 2,
        "importPath": "tests.test_phase1",
        "description": "tests.test_phase1",
        "peekOfCode": "def test_click_tracking():\n    \"\"\"Test click tracking and analytics\"\"\"\n    print(\"\\n\\n📊 TEST 3: Click Tracking & Analytics\")\n    print(\"-\" * 80)\n    # Log some interactions\n    interactions = [\n        (\"Goblin\", \"click\", 1),\n        (\"Crash Landing on You\", \"click\", 2),\n        (\"Goblin\", \"watchlist_add\", None),\n        (\"Hotel Del Luna\", \"click\", 3),",
        "detail": "tests.test_phase1",
        "documentation": {}
    },
    {
        "label": "test_analytics_endpoints",
        "kind": 2,
        "importPath": "tests.test_phase1",
        "description": "tests.test_phase1",
        "peekOfCode": "def test_analytics_endpoints():\n    \"\"\"Test analytics endpoints\"\"\"\n    print(\"\\n\\n📈 TEST 4: Analytics Endpoints\")\n    print(\"-\" * 80)\n    # Test popular dramas\n    print(\"\\n1. Popular Dramas (Last 7 days):\")\n    try:\n        response = requests.get(\n            f\"{BASE_URL}/analytics/popular\", params={\"days\": 7, \"limit\": 5}, timeout=5\n        )",
        "detail": "tests.test_phase1",
        "documentation": {}
    },
    {
        "label": "test_dynamic_alpha_comparison",
        "kind": 2,
        "importPath": "tests.test_phase1",
        "description": "tests.test_phase1",
        "peekOfCode": "def test_dynamic_alpha_comparison():\n    \"\"\"Compare results with different intent types\"\"\"\n    print(\"\\n\\n⚖️  TEST 5: Dynamic Alpha Comparison\")\n    print(\"-\" * 80)\n    queries = [\n        (\"Park Seo-joon drama\", \"actor_based\", \"Lower alpha (more lexical)\"),\n        (\"sad emotional drama\", \"emotion_based\", \"Higher alpha (more semantic)\"),\n        (\"romance drama\", \"genre_browse\", \"Balanced alpha\"),\n    ]\n    for query, expected_intent, description in queries:",
        "detail": "tests.test_phase1",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "tests.test_phase1",
        "description": "tests.test_phase1",
        "peekOfCode": "def main():\n    \"\"\"Run all tests\"\"\"\n    print(\"\\n🚀 Starting Phase 1 Tests...\\n\")\n    try:\n        # Check if backend is running\n        response = requests.get(f\"{BASE_URL}/\", timeout=5)\n        if response.status_code != 200:\n            print(\"❌ ERROR: Backend is not running!\")\n            print(f\"   Please start the backend: cd backend && python app.py\")\n            return",
        "detail": "tests.test_phase1",
        "documentation": {}
    },
    {
        "label": "BASE_URL",
        "kind": 5,
        "importPath": "tests.test_phase1",
        "description": "tests.test_phase1",
        "peekOfCode": "BASE_URL = \"http://127.0.0.1:8001\"\n# Test user\nTEST_USER_ID = \"test_user_phase1\"\nTEST_SESSION_ID = f\"session_{datetime.now().timestamp()}\"\nprint(\"=\" * 80)\nprint(\"SEOULMATE PHASE 1 TEST SUITE\")\nprint(\"=\" * 80)\nprint(f\"Backend: {BASE_URL}\")\nprint(f\"User: {TEST_USER_ID}\")\nprint(f\"Session: {TEST_SESSION_ID}\")",
        "detail": "tests.test_phase1",
        "documentation": {}
    },
    {
        "label": "TEST_USER_ID",
        "kind": 5,
        "importPath": "tests.test_phase1",
        "description": "tests.test_phase1",
        "peekOfCode": "TEST_USER_ID = \"test_user_phase1\"\nTEST_SESSION_ID = f\"session_{datetime.now().timestamp()}\"\nprint(\"=\" * 80)\nprint(\"SEOULMATE PHASE 1 TEST SUITE\")\nprint(\"=\" * 80)\nprint(f\"Backend: {BASE_URL}\")\nprint(f\"User: {TEST_USER_ID}\")\nprint(f\"Session: {TEST_SESSION_ID}\")\nprint(\"=\" * 80)\ndef test_query_intent():",
        "detail": "tests.test_phase1",
        "documentation": {}
    },
    {
        "label": "TEST_SESSION_ID",
        "kind": 5,
        "importPath": "tests.test_phase1",
        "description": "tests.test_phase1",
        "peekOfCode": "TEST_SESSION_ID = f\"session_{datetime.now().timestamp()}\"\nprint(\"=\" * 80)\nprint(\"SEOULMATE PHASE 1 TEST SUITE\")\nprint(\"=\" * 80)\nprint(f\"Backend: {BASE_URL}\")\nprint(f\"User: {TEST_USER_ID}\")\nprint(f\"Session: {TEST_SESSION_ID}\")\nprint(\"=\" * 80)\ndef test_query_intent():\n    \"\"\"Test query intent detection and dynamic weights\"\"\"",
        "detail": "tests.test_phase1",
        "documentation": {}
    },
    {
        "label": "API_URL",
        "kind": 5,
        "importPath": "tests.test_phase2_complete",
        "description": "tests.test_phase2_complete",
        "peekOfCode": "API_URL = \"http://127.0.0.1:8001\"\nprint(\"=\" * 80)\nprint(\"Phase 2 Complete Integration Test\")\nprint(\"=\" * 80)\n# Check API health\nprint(\"\\n1️⃣ Checking API health...\")\ntry:\n    response = requests.get(f\"{API_URL}/\", timeout=3)\n    if response.status_code == 200:\n        data = response.json()",
        "detail": "tests.test_phase2_complete",
        "documentation": {}
    },
    {
        "label": "test_user_id",
        "kind": 5,
        "importPath": "tests.test_phase2_complete",
        "description": "tests.test_phase2_complete",
        "peekOfCode": "test_user_id = f\"test_user_{int(time.time())}\"\nprint(f\"   User ID: {test_user_id}\")\n# Test 3: Rate some dramas to build profile\nprint(\"\\n3️⃣ Rating dramas to build taste profile...\")\ndramas_to_rate = [\n    (\"Hospital Playlist\", 9.5),\n    (\"Good Doctor\", 9.0),\n    (\"Romantic Doctor Kim\", 8.5),\n    (\"Doctor John\", 8.0),\n]",
        "detail": "tests.test_phase2_complete",
        "documentation": {}
    },
    {
        "label": "dramas_to_rate",
        "kind": 5,
        "importPath": "tests.test_phase2_complete",
        "description": "tests.test_phase2_complete",
        "peekOfCode": "dramas_to_rate = [\n    (\"Hospital Playlist\", 9.5),\n    (\"Good Doctor\", 9.0),\n    (\"Romantic Doctor Kim\", 8.5),\n    (\"Doctor John\", 8.0),\n]\nfor drama_title, rating in dramas_to_rate:\n    try:\n        response = requests.post(\n            f\"{API_URL}/profile/{test_user_id}/rate\",",
        "detail": "tests.test_phase2_complete",
        "documentation": {}
    },
    {
        "label": "response",
        "kind": 5,
        "importPath": "tests.test_phase2_complete",
        "description": "tests.test_phase2_complete",
        "peekOfCode": "response = input(\"   Do you want to delete the test user profile? (y/n): \")\nif response.lower() == \"y\":\n    try:\n        response = requests.delete(f\"{API_URL}/profile/{test_user_id}\", timeout=3)\n        if response.status_code == 200:\n            print(\"   ✅ Test profile deleted\")\n        else:\n            print(f\"   ⚠️  Could not delete profile\")\n    except Exception as e:\n        print(f\"   ❌ Error: {str(e)}\")",
        "detail": "tests.test_phase2_complete",
        "documentation": {}
    },
    {
        "label": "profile_manager",
        "kind": 5,
        "importPath": "tests.test_user_profile",
        "description": "tests.test_user_profile",
        "peekOfCode": "profile_manager = UserProfileManager(profiles_dir=\"../tests/test_profiles\")\nprint(\"=\" * 80)\nprint(\"Testing User Profile System (Phase 2)\")\nprint(\"=\" * 80)\n# Test 1: Create new user profile\nprint(\"\\n1️⃣ Creating new user profile...\")\nuser_id = \"test_user_phase2\"\nprofile = profile_manager.load_profile(user_id)\nprint(f\"✅ Created profile for {user_id}\")\nprint(f\"   Statistics: {profile['statistics']}\")",
        "detail": "tests.test_user_profile",
        "documentation": {}
    },
    {
        "label": "user_id",
        "kind": 5,
        "importPath": "tests.test_user_profile",
        "description": "tests.test_user_profile",
        "peekOfCode": "user_id = \"test_user_phase2\"\nprofile = profile_manager.load_profile(user_id)\nprint(f\"✅ Created profile for {user_id}\")\nprint(f\"   Statistics: {profile['statistics']}\")\n# Test 2: Simulate interactions with Medical dramas\nprint(\"\\n2️⃣ Simulating interactions with Medical dramas...\")\nmedical_dramas = [\n    {\n        \"Title\": \"Hospital Playlist\",\n        \"Genre\": \"Medical, Life, Friendship\",",
        "detail": "tests.test_user_profile",
        "documentation": {}
    },
    {
        "label": "profile",
        "kind": 5,
        "importPath": "tests.test_user_profile",
        "description": "tests.test_user_profile",
        "peekOfCode": "profile = profile_manager.load_profile(user_id)\nprint(f\"✅ Created profile for {user_id}\")\nprint(f\"   Statistics: {profile['statistics']}\")\n# Test 2: Simulate interactions with Medical dramas\nprint(\"\\n2️⃣ Simulating interactions with Medical dramas...\")\nmedical_dramas = [\n    {\n        \"Title\": \"Hospital Playlist\",\n        \"Genre\": \"Medical, Life, Friendship\",\n        \"Cast\": \"Jo Jung-suk, Yoo Yeon-seok, Jung Kyung-ho\",",
        "detail": "tests.test_user_profile",
        "documentation": {}
    },
    {
        "label": "medical_dramas",
        "kind": 5,
        "importPath": "tests.test_user_profile",
        "description": "tests.test_user_profile",
        "peekOfCode": "medical_dramas = [\n    {\n        \"Title\": \"Hospital Playlist\",\n        \"Genre\": \"Medical, Life, Friendship\",\n        \"Cast\": \"Jo Jung-suk, Yoo Yeon-seok, Jung Kyung-ho\",\n        \"Director\": \"Shin Won-ho\",\n        \"Description\": \"A heartwarming drama about five doctors who have been friends since medical school\",\n        \"keywords\": \"friendship, medical, heartwarming, realistic\",\n        \"episodes\": \"12\",\n    },",
        "detail": "tests.test_user_profile",
        "documentation": {}
    },
    {
        "label": "top_genres",
        "kind": 5,
        "importPath": "tests.test_user_profile",
        "description": "tests.test_user_profile",
        "peekOfCode": "top_genres = profile_manager.get_top_preferences(user_id, \"genres\", 5)\nprint(\"   Top genres:\")\nfor genre, score in top_genres:\n    print(f\"      {genre}: {score:.2f}\")\n# Test 4: Check actor preferences\nprint(\"\\n4️⃣ Checking learned actor preferences...\")\ntop_actors = profile_manager.get_top_preferences(user_id, \"actors\", 5)\nprint(\"   Top actors:\")\nfor actor, score in top_actors:\n    print(f\"      {actor}: {score:.2f}\")",
        "detail": "tests.test_user_profile",
        "documentation": {}
    },
    {
        "label": "top_actors",
        "kind": 5,
        "importPath": "tests.test_user_profile",
        "description": "tests.test_user_profile",
        "peekOfCode": "top_actors = profile_manager.get_top_preferences(user_id, \"actors\", 5)\nprint(\"   Top actors:\")\nfor actor, score in top_actors:\n    print(f\"      {actor}: {score:.2f}\")\n# Test 5: Check theme preferences\nprint(\"\\n5️⃣ Checking learned theme preferences...\")\ntop_themes = profile_manager.get_top_preferences(user_id, \"themes\", 5)\nprint(\"   Top themes:\")\nfor theme, score in top_themes:\n    print(f\"      {theme}: {score:.2f}\")",
        "detail": "tests.test_user_profile",
        "documentation": {}
    },
    {
        "label": "top_themes",
        "kind": 5,
        "importPath": "tests.test_user_profile",
        "description": "tests.test_user_profile",
        "peekOfCode": "top_themes = profile_manager.get_top_preferences(user_id, \"themes\", 5)\nprint(\"   Top themes:\")\nfor theme, score in top_themes:\n    print(f\"      {theme}: {score:.2f}\")\n# Test 6: Add some Romance dramas\nprint(\"\\n6️⃣ Adding Romance drama interactions...\")\nromance_dramas = [\n    {\n        \"Title\": \"Crash Landing on You\",\n        \"Genre\": \"Romance, Comedy, Drama\",",
        "detail": "tests.test_user_profile",
        "documentation": {}
    },
    {
        "label": "romance_dramas",
        "kind": 5,
        "importPath": "tests.test_user_profile",
        "description": "tests.test_user_profile",
        "peekOfCode": "romance_dramas = [\n    {\n        \"Title\": \"Crash Landing on You\",\n        \"Genre\": \"Romance, Comedy, Drama\",\n        \"Cast\": \"Hyun Bin, Son Ye-jin\",\n        \"Director\": \"Lee Jung-hyo\",\n        \"Description\": \"A South Korean heiress accidentally paraglides into North Korea\",\n        \"keywords\": \"romance, comedy, emotional, heartwarming\",\n        \"episodes\": \"16\",\n    }",
        "detail": "tests.test_user_profile",
        "documentation": {}
    },
    {
        "label": "top_genres",
        "kind": 5,
        "importPath": "tests.test_user_profile",
        "description": "tests.test_user_profile",
        "peekOfCode": "top_genres = profile_manager.get_top_preferences(user_id, \"genres\", 5)\nprint(\"   Top genres:\")\nfor genre, score in top_genres:\n    print(f\"      {genre}: {score:.2f}\")\n# Test 8: Get profile summary\nprint(\"\\n8️⃣ Getting profile summary...\")\nsummary = profile_manager.get_profile_summary(user_id)\nprint(f\"   Persona: {summary['persona']}\")\nprint(f\"   Total interactions: {summary['statistics']['total_interactions']}\")\nprint(f\"   Total watched: {summary['statistics']['total_watched']}\")",
        "detail": "tests.test_user_profile",
        "documentation": {}
    },
    {
        "label": "summary",
        "kind": 5,
        "importPath": "tests.test_user_profile",
        "description": "tests.test_user_profile",
        "peekOfCode": "summary = profile_manager.get_profile_summary(user_id)\nprint(f\"   Persona: {summary['persona']}\")\nprint(f\"   Total interactions: {summary['statistics']['total_interactions']}\")\nprint(f\"   Total watched: {summary['statistics']['total_watched']}\")\nprint(f\"   Avg rating: {summary['statistics']['avg_rating']:.2f}\")\nprint(f\"   Rating style: {summary['statistics']['rating_style']}\")\nprint(f\"   Binge watcher: {summary['viewing_patterns']['binge_watcher']}\")\n# Test 9: Test with different user (Thriller fan)\nprint(\"\\n9️⃣ Creating Thriller fan profile...\")\nthriller_user = \"test_thriller_fan\"",
        "detail": "tests.test_user_profile",
        "documentation": {}
    },
    {
        "label": "thriller_user",
        "kind": 5,
        "importPath": "tests.test_user_profile",
        "description": "tests.test_user_profile",
        "peekOfCode": "thriller_user = \"test_thriller_fan\"\nthriller_dramas = [\n    {\n        \"Title\": \"Signal\",\n        \"Genre\": \"Thriller, Mystery, Crime\",\n        \"Cast\": \"Lee Je-hoon, Kim Hye-soo\",\n        \"Director\": \"Kim Won-seok\",\n        \"Description\": \"Detectives from different time periods communicate via mysterious walkie-talkie\",\n        \"keywords\": \"suspense, mystery, crime, thriller\",\n        \"episodes\": \"16\",",
        "detail": "tests.test_user_profile",
        "documentation": {}
    },
    {
        "label": "thriller_dramas",
        "kind": 5,
        "importPath": "tests.test_user_profile",
        "description": "tests.test_user_profile",
        "peekOfCode": "thriller_dramas = [\n    {\n        \"Title\": \"Signal\",\n        \"Genre\": \"Thriller, Mystery, Crime\",\n        \"Cast\": \"Lee Je-hoon, Kim Hye-soo\",\n        \"Director\": \"Kim Won-seok\",\n        \"Description\": \"Detectives from different time periods communicate via mysterious walkie-talkie\",\n        \"keywords\": \"suspense, mystery, crime, thriller\",\n        \"episodes\": \"16\",\n    },",
        "detail": "tests.test_user_profile",
        "documentation": {}
    },
    {
        "label": "thriller_summary",
        "kind": 5,
        "importPath": "tests.test_user_profile",
        "description": "tests.test_user_profile",
        "peekOfCode": "thriller_summary = profile_manager.get_profile_summary(thriller_user)\nprint(f\"   Thriller fan persona: {thriller_summary['persona']}\")\nprint(f\"   Top genres: {[g[0] for g in thriller_summary['top_genres'][:3]]}\")\nprint(\"\\n\" + \"=\" * 80)\nprint(\"✅ User Profile System Tests Complete!\")\nprint(\"=\" * 80)\nprint(\"\\n📊 Summary:\")\nprint(f\"   - Created 2 user profiles\")\nprint(f\"   - Tested genre, actor, theme preference learning\")\nprint(f\"   - Verified different users have different preferences\")",
        "detail": "tests.test_user_profile",
        "documentation": {}
    }
]